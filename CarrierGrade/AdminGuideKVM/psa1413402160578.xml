<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE task-wr PUBLIC "-//WindRiver.com//DTD DITA 1.2 Wind River General Task//EN" "task-wr.dtd">
<task-wr domains="(topic task task-wr)                            (topic hi-d)                            (topic pr-d)                            (topic sw-d)                            (topic ui-d)                            (topic wr-sw-d)                            (topic xml-d)   " id="psa1413402160578" xml:lang="en-us" xmlns:ditaarch="http://dita.oasis-open.org/architecture/2005/">
<!-- Modification History
        
-->
    <title ixia_locid="1">PCI Passthrough Ethernet Interfaces</title>
    <shortdesc ixia_locid="2">A <term ixia_locid="3">passthrough</term> Ethernet interface is a physical PCI Ethernet NIC on a
        compute node to which a virtual machine is granted direct access. This minimizes packet
        processing delays but at the same time demands special operational
        considerations.</shortdesc>
    <prolog>
        <author ixia_locid="4">Pedro Sanchez</author>
    </prolog>
    <taskbody>
        <context id="context_N10023_N10020_N10001" ixia_locid="5">
            <p ixia_locid="6">For all purposes, a PCI passthrough interface behaves as if it were
                physically attached to the virtual machine. Therefore any potential throughput
                limitations coming from the virtualized environment, such as the ones introduced by
                internal copying of data buffers, are eliminated. However, by bypassing the
                virtualized environment, the use of PCI passthrough Ethernet devices introduces
                several restrictions that must be taken into consideration. They include:</p>
            <ul id="ul_mjs_m52_tp">
                <li ixia_locid="7">
                    <p ixia_locid="8">no support for LAG, QoS, ACL, or host interface monitoring</p>
                </li>
                <li ixia_locid="9">
                    <p ixia_locid="10">no support for live migration</p>
                </li>
                <li ixia_locid="11">
                    <p ixia_locid="12">no access the compute node's AVS switch</p>
                </li>
            </ul>
            <p ixia_locid="14">A passthrough interface bypasses the compute node's AVS switch
                completely, and is attached instead directly to the provider network's access
                switch. Therefore, proper routing of traffic to connect the passthrough interface to
                a particular tenant network depends entirely on the VLAN tagging options configured
                on both the passthrough interface and the access port on the switch.</p>
            <p ixia_locid="15">The access switch routes incoming traffic based on a VLAN ID, which ultimately
                determines the tenant network to which the traffic belongs. The VLAN ID is either
                explicit, as found in incoming tagged packets, or implicit, as defined by the access
                port's default VLAN ID when the incoming packets are untagged. In both cases the
                access switch must be configured to process the proper VLAN ID, which therefore has
                to be known in advance.</p>
            <p ixia_locid="16">In the following example a new virtual machine is launched by user
                    <nameliteral ixia_locid="17">user1</nameliteral> on tenant <nameliteral ixia_locid="18">tenant1</nameliteral>, with a passthrough interface connected to
                the tenant network <nameliteral ixia_locid="19">net0</nameliteral> identified with
                VLAN ID 10.</p>
        </context>
        <prereq id="prereq_N10065_N10020_N10001" ixia_locid="20">
            <p ixia_locid="21">The exercise assumes that the underlying provider network
                    <nameliteral ixia_locid="22">group0-data0</nameliteral> exists already, and that VLAN ID 10 is a
                valid segmentation ID assigned to <nameliteral ixia_locid="23">tenant1</nameliteral>.</p>
        </prereq>
        <steps>
            <step id="step_N10079_N10076_N10020_N10001" ixia_locid="24">
                <cmd ixia_locid="25">Log in as the <nameliteral ixia_locid="26">admin</nameliteral> user to the web management
                    interface.</cmd>
            </step>
            <step id="step_N1009B_N10088_N10024_N10001" ixia_locid="116">
                <cmd ixia_locid="117">Lock the compute node you want to configure.</cmd>
            </step>
            <step id="step_N10086_N10076_N10020_N10001" ixia_locid="27">
                <cmd ixia_locid="28">Configure the Ethernet interface to be used as a PCI
                    passthrough interface.</cmd>
                <info ixia_locid="118">
                    <p ixia_locid="119">Select the <wintitle ixia_locid="31">System
                            Inventory</wintitle> window from the <uicontrol ixia_locid="32">Admin</uicontrol> panel, click the <uicontrol ixia_locid="33">Hosts</uicontrol> tab, click the name of the compute node where the PCI
                        interface is available, click the <uicontrol ixia_locid="34">Interfaces</uicontrol> tab, and finally click the <uicontrol ixia_locid="36">Edit Interface</uicontrol> button associated with the
                        interface you want to configure. Fill in the window as illustrated
                        below:</p>
                    <fig id="fig_hfk_cfh_rr" ixia_locid="120">
                        <image href="psa1428772332800.image" id="image_whc_5kh_rr" ixia_locid="122" width="4in">
                            <alt ixia_locid="123">Edit PCI Passthrough Interface</alt>
                        </image>
                    </fig>
                    <p ixia_locid="124">In this example, Ethernet interface <nameliteral ixia_locid="42">eth8</nameliteral> is assigned the network type <term ixia_locid="43">pci-passthrough</term>, and configured as connected to provider network
                            <nameliteral ixia_locid="44">group0-data0</nameliteral>. Click the
                            <uicontrol ixia_locid="45">Save</uicontrol> button to proceed.</p>
                    <p ixia_locid="46">The interface can also be configured from the CLI as
                        illustrated below:</p>
                    <codeblock ixia_locid="108"><systemoutput ixia_locid="111">~(keystone_admin)$ </systemoutput><userinput ixia_locid="115">system host-if-modify \
-nt pci-passthrough -p group0-data0 compute-0 eth8</userinput></codeblock>
                </info>
            </step>
            <step id="step_N100E9_N10076_N10020_N10001" ixia_locid="51">
                <cmd ixia_locid="52">Create the <nameliteral ixia_locid="53">net0</nameliteral>
                    tenant network</cmd>
                <info ixia_locid="54">
                    <p ixia_locid="55">Select the <wintitle ixia_locid="56">Networks</wintitle>
                        window from the <uicontrol ixia_locid="57">Admin</uicontrol> panel, click
                        the <uicontrol ixia_locid="58">Networks</uicontrol> tab, and then click the
                            <uicontrol ixia_locid="59">Create Network</uicontrol> button. Fill in
                        the <wintitle ixia_locid="60">Create Network</wintitle> window as
                        illustrated below. You must ensure that:</p>
                    <ul id="ul_pcn_vb4_tp">
                        <li ixia_locid="61">
                            <p ixia_locid="62">The <nameliteral ixia_locid="63">tenant1</nameliteral> tenant has access to the tenant network,
                                either assigning it as the owner, as in the illustration (using
                                    <uicontrol ixia_locid="107">Project</uicontrol>), or by enabling the shared
                                flag.</p>
                        </li>
                        <li ixia_locid="64">
                            <p ixia_locid="65">The segmentation ID is set to 10. </p>
                        </li>
                    </ul>
                    <fig id="fig_kwr_hd4_tp" ixia_locid="66">
                        <image href="psa1413406273455.image" id="image_ofd_kd4_tp" ixia_locid="67" placement="inline" width="4in">
                            <alt ixia_locid="68">Creating a tenant network for use with PCI
                                passthrough devices</alt>
                        </image>
                    </fig>
                    <p ixia_locid="69">Click the <uicontrol ixia_locid="70">Create Network</uicontrol> button to proceed.</p>
                </info>
            </step>
            <step id="step_N10144_N10076_N10020_N10001" ixia_locid="71">
                <cmd ixia_locid="72">Configure the access switch.</cmd>
                <info ixia_locid="73">
                    <p ixia_locid="104">Configure the physical port on the access switch used to
                        connect to Ethernet interface <nameliteral ixia_locid="75">eth8</nameliteral> as an access port with default VLAN ID of 10.
                        Traffic across the connection is therefore untagged, and effectively
                        integrated into the targeted tenant network.</p>
                    <p ixia_locid="76">You can also use a trunk port on the access switch so that it
                        handles tagged packets as well. However, this opens the possibility for
                        guest applications to join other tenant networks using tagged packets with
                        different VLAN IDs, which might compromise the security of the system. See
                            <xref href="jow1404333739778.xml" ixia_locid="143"/> for other details regarding the
                        configuration of the access switch.</p>
                </info>
            </step>
            <step id="step_N101A0_N10088_N10024_N10001" ixia_locid="125">
                <cmd ixia_locid="126">Unlock the compute node.</cmd>
            </step>
            <step id="step_N1015D_N10076_N10020_N10001" ixia_locid="77">
                <cmd ixia_locid="78">Launch the virtual machine.</cmd>
                <substeps id="substeps_snp_klt_tp">
                    <substep ixia_locid="79">
                        <cmd ixia_locid="80">Log in as user <nameliteral ixia_locid="81">user1</nameliteral> to the web management
                            interface.</cmd>
                    </substep>
                    <substep ixia_locid="82">
                        <cmd ixia_locid="83">Configure the network interfaces for the new virtual machine.</cmd>
                        <info ixia_locid="84">
                            <p ixia_locid="85">Open the <wintitle ixia_locid="86">Launch
                                    Instance</wintitle> dialog by clicking the <uicontrol ixia_locid="87">Launch Interface</uicontrol> button on the
                                    <wintitle ixia_locid="88">Instances</wintitle> window. Configure
                                the necessary options for the new virtual machine. In particular,
                                click the <uicontrol ixia_locid="89">Networking</uicontrol> tab and
                                add a PCI passthrough interface on the tenant network <nameliteral ixia_locid="90">net0</nameliteral>, as illustrated below. Add
                                other network interfaces as needed.</p>
                            <fig id="fig_yxy_t1g_tp" ixia_locid="91">
                                <image href="psa1413311389905.image" id="image_dbb_4dg_tp" ixia_locid="93" placement="inline" width="5.5in">
                                    <alt ixia_locid="94">Assigning Passthrough PCI Ethernet
                                        Devices</alt>
                                </image>
                            </fig>
                            <p ixia_locid="95">Click the <uicontrol ixia_locid="96">Launch</uicontrol> button to proceed.</p>
                            <p ixia_locid="97">Passthrough interfaces can be attached from the CLI when booting a
                                new virtual machine, as illustrated below:</p>
                            <codeblock ixia_locid="98"><systemoutput ixia_locid="114">~(keystone_admin)$ </systemoutput><userinput ixia_locid="100">nova boot \
--nic net-id=704e9f3b,vif-model=pci-passthrough my-new-vm</userinput></codeblock>
                        </info>
                    </substep>
                </substeps>
            </step>
        </steps>
        <result id="result_N101C1_N10020_N10001" ixia_locid="101">
            <p ixia_locid="102">The new virtual machine instance is up now. It has a PCI passthrough
                connection to the <nameliteral ixia_locid="103">net0</nameliteral> tenant network
                identified with VLAN ID 10.</p>
        </result>
        <postreq id="postreq_N1023B_N10024_N10001" ixia_locid="127">
            <p ixia_locid="128">Access switches must be properly configured to ensure that virtual
                machines using PCI-passthrough or SR-IOV Ethernet interfaces (the latter discussed
                in <xref href="psa1428687672712.xml" ixia_locid="129"/>) have the expected
                connectivity. In a common scenario, the virtual machine using these interfaces
                connects to external end points only, that is, it does not connect to other virtual
                machines in the same cluster. In this case:</p>
            <ul id="ul_pz2_w4w_rr">
                <li ixia_locid="130">
                    <p ixia_locid="131">Traffic between the virtual machine and the access switch
                        can be tagged or untagged.</p>
                </li>
                <li ixia_locid="144">
                    <p ixia_locid="146">The connecting port on the access switch is part of a
                        port-based VLAN.</p>
                </li>
                <li ixia_locid="145">
                    <p ixia_locid="147">If the port is tagged, the allowed VLAN ID range must not
                        overlap with VLAN ID ranges used by the AVS ports. </p>
                </li>
                <li ixia_locid="134">
                    <p ixia_locid="135">The port-based VLAN provides the required connectivity to external switching
                        and routing equipment needed by guest applications to establish connections
                        to the intended end points.</p>
                </li>
            </ul>
            <p ixia_locid="136">For connectivity to other virtual machines in the cluster the
                following configuration is also required:</p>
            <ul id="ul_ngs_nvw_rr">
                <li ixia_locid="137">
                    <p ixia_locid="138">The VLAN ID used for the tenant network, 10 in this example, and the default
                        port VLAN ID of the access port on the switch are the same. This ensures
                        that incoming traffic from the virtual machine is tagged internally by the
                        switch as belonging to VLAN ID 10, and switched to the appropriate exit
                        ports.</p>
                </li>
                <li ixia_locid="139">
                    <p ixia_locid="140">The target virtual machines are reachable through another port on the compute
                        node, which is managed by the AVS.</p>
                </li>
                <li ixia_locid="141">
                    <p ixia_locid="142">That other port is configured as usual, as a VLAN trunk
                        port, and the tenant network's VLAN ID (10) is included in the tagged range.
                        This ensures that VLAN 10 is common to both the passthrough/SR-IOV interface
                        and the AVS port.</p>
                </li>
            </ul>
        </postreq>
    </taskbody>
</task-wr>