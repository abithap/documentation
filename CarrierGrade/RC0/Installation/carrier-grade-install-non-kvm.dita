<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic10581">
<title>HP Helion <tm tmtype="reg">OpenStack</tm> Carrier Grade 1.1: Deploying the Non-KVM
    Region</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
</metadata>
</prolog>
<body>
<p>
<!--UNDER REVISION-->
 <!--./CarrierGrade/Installation/carrier-grade-install-pb-hlm-vm.md-->
 <!--permalink: /helion/openstack/carrier/install/pb/hlm-vm/--></p>
  <p>The first phase of the HP Helion Openstack Carrier Grade installation involves creating a virtual machine for the Helion Lifecycle Management (HLM) and then deploying the HP Helion Openstack cloud.</p>

<section id="prepare"> <title>Prepare the system for deployment</title>
<p>Use the following steps to prepare the server on which the HLM VM will be deployed (the HLM host):</p>
<ol>

  <li>Edit the <codeph>/root/infra-ansible-playbooks/group_vars/all</codeph> file for your
          environment. For information on each variable, refer to the comments in the file with each
          variable. Make sure the <codeph>hlm_kvm_host</codeph> value is configured properly.</li>
  <li id="hosts">Check the hosts file <codeph>/root/infra-ansible-playbooks/hosts</codeph> file to
    enter the IP address of the vibr0 interface in the <codeph>hlm_kvm_host</codeph> field, as shown in the following example. Make sure the DCM network
          details are correct. Also, verify the CLM IP address in this file.</li>
</ol>
<codeblock>  [hlm_kvm_host]
  192.168.122.1 </codeblock>
</section>
<section id="deploy-the-hlm-and-vsd-vm">
      <title>Deploy the HLM Virtual Machine</title>
      <p>Use the following steps to deploy the HLM VM on the HLM Host using Ansible playbooks.</p>
      <ol>
        <li>Make sure the Ansible playbook file is not in executable mode.</li>
        <li>Execute the following
          command:<codeblock>ansible-playbook -i hosts setup_hlm_onBM.yml</codeblock> The command
          will do the following:<ul>
            <li>Copy both installation files (tar balls) to the HLM host, decrypt, and extract the
              files.</li>
            <li>Execute the <codeph>updatepackages</codeph> command.</li>
            <li>Execute the <codeph>prepareenv</codeph> command.</li>
            <li>Execute the <codeph>Init cobbler</codeph> command.</li>
            <li>Execute the <codeph>Importiso</codeph> command.<p>You will see similar message when
                the playbook is run successful:</p></li>
          </ul>
          <image href="../../media/CGH-Install-Ansible.png" id="image_jmr_dds_rs"/></li>
        <li>Locate the IP address for the HLM VM in the
            <codeph>/root/infra-ansible-playbooks/group_vars/all</codeph> file of the HLM host under
          <codeph>hlm_clmstaticip</codeph> field.</li> 
      </ol>    
</section>
  
<!--<section> <title>Configuring the VSD node, creating user and applying License</title>
  <p>During the <i>Deploy the HLM Cloud and VSD VM</i> section, a vritual machine is created to host VSD. </p>
<p>You need to log into the VSD node (using SSH), then create a default user and apply the required license.</p>
  
<p>After logging into the VDS node, execute the following command to launch a console window:</p>
<codeblock>virsh console vsd</codeblock>
<p>You should see the status as below from VSD VM.</p>
<p>
  <image href="../../media/CGH-install-virsh-vsd.png"/>
</p>
</section>
<section id="vsd-performance-workaround"> <title>VSD Performance workaround</title>
<p>By default VSD has only 8G memory. For better performance behavior, you can update the VSD memory to 16G.</p>
<ol>
<li>From HLM host, execute the following command to power down the VSD node:
          VM:<codeblock>virsh destroy vsd</codeblock></li>
<li>Execute the following command to edit the memory setting in the VSD XML
          file:<codeph>virsh edit vsd 

Current value 
    &lt;memory unit='KiB'&gt;8388608&lt;/memory&gt;
    &lt;currentMemory unit='KiB'&gt;8388608&lt;/currentMemory&gt;

Change to 
    &lt;memory unit='KiB'&gt;16777216&lt;/memory&gt;
    &lt;currentMemory unit='KiB'&gt;16777216&lt;/currentMemory&gt;
</codeph></codeblock></li>
<li>Save the value<codeph>virsh save vsd
</codeph></li>
<li>Use the following command to start the
            VM:<codeph>virsh start vsd
</codeph><p>It can take 15 minutes or
            more to sync with NTP and to get all the other VSD services up.</p></li>
</ol>
</section>
<section id="launch-vsd-dashboard"> <title>Launch VSD Dashboard</title>
<p>On the HLM host:</p>
<ol>
<li>Using an browser such as Chrome or FireFox, navigate to the DCM IP of VSD.</li>
<li>In the log in page, enter the default
          credentials:<codeblock>User Name: Csproot 
Password: csproot 
Org: csp 
VSD Server : auto 
</codeblock></li>
</ol>
</section>
<section id="applying-the-license"> <title>Applying the License</title>
<p>To install the required DCN license:</p>
<ol>
<li>From VSD Dashboard, click the <b>Open VSP Configuration</b> tab on the top right corner of the
          dashboard.</li>
<li>Click the <b>Licenses</b> tab and click <b>+</b>.</li>
<li>Copy and paste the license that you have receive into the screen that displays.</li>
</ol>
</section>
<section id="create-user-for-plugin-login"> <title>Create User for Plugin Login</title>
<p>You must create a user and add it to CMS Group.</p>
<ol>
<li>From VSD Dashboard, click the <b>Open VSP Configuration</b> tab on the top right corner of the
          dashboard.</li>
<li>Click the <b>CSP Users</b> tab and click <b>+</b>.</li>
<li>Create a user named <codeph>OSadmin</codeph> with the password <codeph>OSadmin</codeph>.</li>
<li>Add the user to the <codeph>CMS Group</codeph>.</li>
</ol>
</section>
-->
  <section id="configure-a-json-file-for-installation"> <title>Configure a JSON file for installation</title>
<p>The HP Helion OpenStack deployment requires a JSON file. Use the following steps to install and
        edit the file.</p>
<ol>
<li>Login to HLM VM.
            <codeblock>ssh &lt;HLM_VM_IP>
where: HLM_VM_IP is the IP of the HLM VM. </codeblock><p>Use
            the default credentials:
          <codeblock>User Name: root
Password: cghelion</codeblock></p></li>
    
<li>On the HLM VM, change to the home directory.<codeblock>cd ~</codeblock></li>
<li>Provision and configure your HP Helion OpenStack
            VM.<codeblock>hnewcloud  &lt;cloudname&gt; &lt;denver&gt;</codeblock><p>Where:</p><ul>
            <li><codeph>&lt;cloudname&gt;</codeph> is the name of the cloud to create</li>
              <li><codeph>&lt;denver&gt;</codeph> is the name of the template to use. The
              installation kit includes the fully-tested <codeph>denver</codeph> template.</li>
          </ul><p>The command creates the <codeph>&lt;cloudname&gt;</codeph> directory, which will
            contain a JSON template file <codeph>node-provision.json</codeph>. This template
            supplies input values to the <codeph>hprovision</codeph> script, later in the
            installation.</p></li>
<li>Edit <codeph>node-provision.json</codeph> file based on following guidelines:<table>
            <tgroup cols="2">
              <colspec colname="col1" colsep="1" rowsep="1"/>
              <colspec colname="col2" colsep="1" rowsep="1"/>
              <thead>
                <row>
                  <entry colsep="1" rowsep="1">Field</entry>
                  <entry colsep="1" rowsep="1">Baremetal</entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>name</entry>
                  <entry>Name of the system you want to add</entry>
                </row>
                <row>
                  <entry>Pxe-mac-address</entry>
                  <entry>MAC address of the interface you want to PXE boot onto. This is not same as
                    iLO MAC address,</entry>
                </row>
                <row>
                  <entry>Pxe-interface</entry>
                  <entry>The name of the interface on which PXE boot should occur. For example: <codeph>eth0</codeph></entry>
                </row>
                <row>
                  <entry>pm_type</entry>
                  <entry>ipmilan </entry>
                </row>
                <row>
                  <entry>pm_ip</entry>
                  <entry>Power management IP (iLO ip)</entry>
                </row>
                <row>
                  <entry>pm_user</entry>
                  <entry>Power management user (iLO username)</entry>
                </row>
                <row>
                  <entry>pm_pass</entry>
                  <entry>Power management password (iLO password)</entry>
                </row>
                <row>
                  <entry>node_group</entry>
                  <entry>Enter the same value as <codeph>node-type</codeph> in the <codeph>nodes.json</codeph>
                    file used during cloud deployment. For example: `CCN-001-001`.</entry>
                </row>
                <row>
                  <entry>failure_zone, vendor, model, os_partition_size, data_partition_size</entry>
                  <entry>Enter the same value as for these fields an in the <codeph>nodes.json</codeph> file used
                    during cloud deployment</entry>
                </row>
              </tbody>
            </tgroup>
          </table><p>To see a sample <codeph>node-provision.json</codeph> file, see <xref
              href="../../CarrierGrade/Installation/carrier-grade-install-pb-hlm-vm-json.dita">Create the HLM Virtual Machine</xref>.</p></li>
</ol>
</section>
<section id="pxe-boot"> <title>Configure PXE boot</title>
<p>After you edit the <codeph>node-provision.json</codeph> file, you must enable one-time PXE boot
        on the servers set the correct boot order. Execute the following on the HLM VM:</p>
<ol>
<li>Use the following command to install the <codeph>python-hpilo</codeph> module on HLM
  VM:<codeblock>pip install python-hpilo</codeblock><p>
            <codeph>python-hpilo</codeph> is a python library and command-line tool for
          iLO.</p></li>
<li>Copy the <codeph>ilopxebootonce.py</codeph> from the
            <systemoutput>/root/cg-hlm/dev-tools/ilopxebootonce.py</systemoutput> to the directory
          where you have the <codeph>node-provision.json</codeph> file.</li>
<li>Execute the following script:
  <codeblock>python ilopxebootonce.py node-provision.json</codeblock></li>
</ol>
<p>After the script is run, the <codeph>Current One-Time Boot Option</codeph> is set to <codeph>Network Device 1</codeph> on all the servers listed in <codeph>node-provision.json</codeph> file.</p>
</section>
<section id="create-a-new-cloud-template-and-bring-the-cloud-nodes-up"> <title>Create new cloud template and bring the cloud nodes up</title>
<ol>
<li>Use the following script to start the provisioning of the HP Helion OpenStack
            cloud:<p>hprovision <codeph>&lt;cloudname&gt;</codeph>
          </p><p>Where:</p><ul>
            <li><codeph>&lt;cloudname&gt;</codeph> is the name of the cloud to create</li>
          </ul><p>This script will PXE boot the nodes specified in
              <codeph>node-provision.json</codeph> file. The script also tracks the PXE boot
            completion process and will create the <codeph>nodes.json</codeph> file in the
            directory. </p></li>
        <li>Make sure the nodes are booted up.</li>
  <li>Update the <codeph>node-provision.json</codeph> file used in the <xref type="section"
            href="#topic10581/pxe-boot">previous step</xref>.<p>a. Change to the
              <codeph>&lt;cloudname&gt;</codeph>
            directory:</p><codeblock>cd ~/&lt;cloudname&gt;</codeblock><p>b. Once the baremetal
            nodes are provisioned, make sure the <codeph>nodes.json</codeph>  file is generated and
            that you can establish a password-less SSH connection to these nodes from HLM
          VM.</p></li>
<li>Modify the <codeph>environment.json</codeph> file to configure the VLANs and network addresses
          as appropriate for your environment. Set the following for the CLM, CAN, and BLS
          network:<codeblock>"cidr": 
"start-address": </codeblock> The three controller nodes
          should have CLM, CAN, EXT, BLS on eth0 and TUL on eth1. <!--Hiding for RC0 
              <p>The two compute nodes should have CLM, EXT, BLS on eth0 and TUL on eth1.</p>
           -->
  <p> 
            <b>Example:</b>
          </p>

  <pre>{</pre><pre>    "product": {</pre><pre>        "version": 1</pre><pre>    },</pre><pre> </pre><pre>    "node-type": [</pre><pre>        {</pre><pre>            "name": "CCN",</pre><pre>            "interface-map": [</pre><pre>                {</pre><pre>                    "name": "INTF0",</pre><pre>                    "ethernet-port-map": {</pre><pre>                        "interface-ports": [ "eth0" ]</pre><pre>                    },</pre><pre>                    "logical-network-map": [</pre><pre>                        {</pre><pre>                            "name": "CLM",</pre><pre>                            "type": "vlan",</pre><pre>                            "segment-id": "502",</pre><pre>                            "network-address": {</pre><pre>                                "cidr": "10.50.2.0/24",</pre><pre>                                "start-address": "10.50.2.10",</pre><pre>                                "gateway": "10.50.2.1"</pre><pre>                            }</pre><pre>                        },</pre><pre>                        {</pre><pre>                            "name": "CAN",</pre><pre>                            "type": "vlan",</pre><pre>                            "segment-id": "504",</pre><pre>                            "network-address": {</pre><pre>                                "cidr": "10.50.4.0/24",</pre><pre>                                "start-address": "10.50.4.10"</pre><pre>                            }</pre><pre>                        },</pre><pre>                        {</pre><pre>                            "name": "BLS",</pre><pre>                            "type": "vlan",</pre><pre>                            "segment-id": "76",</pre><pre>                            "network-address": {</pre><pre>                                "cidr": "172.16.76.0/19",</pre><pre>                                "start-address": "172.16.76.10"</pre><pre>                            }</pre><pre>                        }</pre><pre>                    ]</pre><pre>                }</pre><pre>            ]</pre><pre>        }</pre><pre>    ]</pre><pre>}</pre><p>

            <b>NOTE:</b> The Helion Configuration Processor assigns the first address of the CLM
            address range to itself for serving python and debian repositories. Make sure that you
            set the first IP address of the CLM range for the eth2 (CLM) address of the HLM
            node.</p></li>
<li>Modify the <codeph>definition.json</codeph> file: <ol>
            <li>Set the number of compute systems to 2.
              <codeblock>"count": 2, //number of computes in the resource pool</codeblock></li>
  <li>Update the <codeph>ansible-vars</codeph> section with all the information based on your
              setup.</li>
  <li>Make sure you have two NTP entries in the <codeph>upstream_ntp_servers</codeph> fields in the
                <codeph>definition.json</codeph> file as seen in the following example. If you have
              only one NTP server in your environment, specify the same NTP server twice. Example:
              <codeblock>{
    "product": {
      "version": 1
      },
    
    "cloud": {
      "name": "b44tb4",
      "nickname": "b44tb4",
      "server-config": "nodes.json",
      "environment": "environment.json",
      "network-config": ".hos/lnet-control-data.json"
    },
    
    "failure-zones": [
      {
        "name": "fz1"
      },
      {
        "name": "fz2"
      },
      {
        "name": "fz3"
      }
    ],
    
    "control-planes": [
      {
        "file": ".hos/ccp-1x3-ss.json",
        "resource-nodes": []
      }
    ],
    
    "ansible-vars": {
      "dns_address": "10.1.2.44",
      "dns_domain_name": "helion.cg",
      "ldap_url": "10.1.2.44",
      "ldap_username": "admin",
      "ldap_password": "admin",
      "ldap_domain": "dc=helioncg,dc=local",
      "ldap_ou": "CGTestUsers",
      "ldap_nova_password": "nova",
      "ldap_nova_user": "nova",
      "ldap_neutron_password": "neutron",
      "ldap_neutron_user": "neutron",
      "ldap_cinder_password": "cinder",
      "ldap_cinder_user": "cinder",
      "ldap_glance_password": "glance",
      "ldap_glance_user": "glance",
      "ldap_enabled": 1,
      "upstream_ntp_servers": [
        "10.1.2.44",
        "16.110.135.123",
        "2.debian.pool.ntp.org"
      ],
      "ssl_cert_file": "ca.crt",
      "ssl_key_file": "cakey.pem",
      "ssl_passphrase": "cghelion"
     },
    
    "wr-vars": {
      "database_storage": 50,
      "backup_storage": 300,
      "image_storage": 250,
      "region_name": "RegionOne",
      "logical_interface": [
        {
          "lag_interface": "N",
          "interface_mtu": 1500,
          "interface_ports": [
              "eth0"
          ],
           "network": [
              {
                  "ip_start_address": "10.50.2.51",
                  "ip_end_address": "10.50.2.99",
                  "name": "CLM"
              },
              {
                  "ip_start_address": "172.16.76.150",
                  "ip_end_address": "172.16.76.199",
                  "name": "BLS"
               },
               {
                  "ip_start_address": "10.50.4.51",
                  "ip_end_address": "10.50.4.99",
                  "gateway": "10.50.4.1",
                  "name": "CAN"
                }
            ]
        }
    ],
    "pxeboot_cidr": "10.50.1.0/24",
    "license_file_name": "license.lic"
    }
 }
</codeblock></li>
          </ol></li>
  
  <li>Use the following steps to modify to the <codeph>cinder/blocks</codeph> directory for your cloud: 
  <ul>
    <li>Change to the <codeph>cinder/blocks</codeph> directory:
      <codeblock>cd ~/&lt;cloudname>/services/cinder/blocks</codeblock>
      Where &lt;cloudname> is the name you assigned to the cloud.</li>
    <li>Copy the <codeph>cinder_conf_default.hp3parSample</codeph> file to the
                <codeph>cinder_conf_default</codeph> file and edit the file to configure to 3PAR
              settings. For example:
              <codeblock>hp3par_api_url=https://&lt;hp3par_ip>:8080/api/v1
hp3par_username=&lt;hp3par_user>
hp3par_password=&lt;hp3par_user_password
hp3par_cpg=bronze
san_ip=&lt;san_ip>
san_login=&lt;san_user>
san_password=&lt;san_password>
hp3par_iscsi_ips=&lt;iscsi_ip1>,&lt;iscsi_ip2>,&lt;iscsi_ip3>,&lt;iscsi_ip4>
volume_driver=cinder.volume.drivers.san.hp.hp_3par_iscsi.HP3PARISCSIDriver
hp3par_debug=False
hp3par_iscsi_chap_enabled=false</codeblock></li></ul></li>            
<li>Once you have correctly edited all the json Cloud Model files, run the HP Helion OpenStack
          Configuration Processor: <codeblock>hcfgproc -d definition.json</codeblock><p>The
              <codeph>hcfgproc</codeph> script gets installed in <codeph>/usr/local/bin</codeph> by
            the <codeph>prepare-env</codeph> script. The script generates a <codeph>clouds/</codeph>
            directory within the directory. </p></li>
<li>Review the CloudDiagram, <codeph>hosts.hf</codeph>, and
            <codeph>net/interfaces.d/eth.cfg</codeph> files to make sure the network settings are
          correct.</li>
<li>Initialize network interfaces on all the cloud nodes using the following command:
            <codeblock><codeph>hnetinit &lt;cloudname&gt;</codeph></codeblock><p>You can run this
            command from any directory.</p><p>After this command completes, all cloud nodes and CLM
            network interfaces should be set correctly.</p></li>

<li>Use the following command to deploy the cloud:
            <codeblock><codeph>hdeploy &lt;cloudname&gt;</codeph></codeblock><p>Once cloud
            deployment is successfully complete, there will be 3 controller nodes in the non-KVM
            region.</p></li>

</ol>



</section>
<section id="next-step"> <title>Next Step</title>
<p>
        <xref href="carrier-grade-install-kvm-cloud-rc0.dita">Deploying the KVM Region</xref>
      </p>
<p>
  <xref type="section" href="#topic10581"> Return to Top </xref>
</p>
<!-- ===================== horizontal rule ===================== -->
</section>
</body>
</topic>
