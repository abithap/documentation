<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic31295">
<title>HP Helion 1.1 Development Platform: Detailed Configuration</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HP Helion Development Platform"/>
<othermeta name="product-version" content="HP Helion Development Platform 1.1"/>
<othermeta name="role" content="Application Developer"/>
<othermeta name="role" content="ISV Developer"/>
<othermeta name="role" content="Service Developer"/>
<othermeta name="role" content="Network Administrator"/>
<othermeta name="role" content="Systems Administrator"/>
<othermeta name="role" content="Security Engineer"/>
<othermeta name="role" content="Jayme P"/>
<othermeta name="product-version1" content="HP Helion Development Platform"/>
<othermeta name="product-version2" content="HP Helion Development Platform 1.1"/>
</metadata>
</prolog>
<body>
<p>
<!--PUBLISHED-->
 <!--./devplatform/helion/admin/server/1.1configuration.md-->
 <!--permalink: /helion/devplatform/1.1/als/admin/server/configuration/--></p>
<p>

</p>
<p>After booting the VM, run <i>kato process ready all</i> before starting the following configuration steps. This command returns <b>READY</b> when all configured system processes have started, and is particularly important when using <i>kato</i> commands in automated configuration scripts which run immediately after boot (the
<xref href="../../../../devplatform/helion/admin/reference/1.1kato-ref.dita#kato-command-ref-process-ready" type="section"  >
<i>--block</i>
</xref>
option is useful in this scenario).</p>
<p>
<b>Warning</b>: All  <i>kato</i>  commands should be run as the 'helion' system user, <b>not as root</b>. Kato will prompt for the 'helion' user password if sudo permissions are required for a specific operation.</p>
<ul>
<li>
<xref type="section" href="#topic31295/changing-the-password">Changing the Password</xref>
</li>
<li>
<xref type="section" href="#topic31295/network-setup">Network Setup</xref>

<ul>
<li>
<xref type="section" href="#topic31295/changing-the-hostname">Changing the Hostname</xref>
</li>
<li>
<xref type="section" href="#topic31295/changing-ip-addresses">Changing IP Addresses</xref>
</li>
<li>
<xref type="section" href="#topic31295/setting-a-static-ip">Setting a Static IP</xref>
</li>
<li>
<xref type="section" href="#topic31295/modifying-etc-hosts">Modifying the hosts file</xref>
</li>
<li>
<xref type="section" href="#topic31295/server-config-dns">DNS</xref>
</li>
<li>
<xref type="section" href="#topic31295/dynamic-dns">Dynamic DNS</xref>
</li>
<li>
<xref type="section" href="#topic31295/alternate-dns-techniques">Alternate DNS Techniques</xref>

<ul>
<li>
<xref type="section" href="#topic31295/xip-io">xip.io</xref>
</li>
<li>
<xref type="section" href="#topic31295/dnsmasq">dnsmasq</xref>
</li>
<li>
<xref type="section" href="#topic31295/adding-dns-nameservers">Adding DNS Nameservers</xref>
</li>
<li>
<xref type="section" href="#topic31295/tcp-udp-port-configuration">TCP/UDP Port Configuration</xref>
</li>
<li>
<xref type="section" href="#topic31295/http-proxy">Upstream HTTP Proxy Settings</xref>
</li>
<li>
<xref type="section" href="#topic31295/staging-cache-app-http-proxy">Staging Cache &amp; App HTTP Proxy</xref>
</li>
</ul>
</li>
<li>
<xref type="section" href="#topic31295/vm-filesystem-setup">VM Filesystem Setup</xref>
</li>
<li>
<xref type="section" href="#topic31295/helion-data-services-vs-high-availability-databases">Application Lifecycle Service Data Services vs. High Availability Databases</xref>
</li>
<li>
<xref type="section" href="#topic31295/https-ssl">HTTPS &amp; SSL</xref>

<ul>
<li>
<xref type="section" href="#topic31295/using-your-own-ssl-certificate">Using your own SSL certificate</xref>
</li>
<li>
<xref type="section" href="#topic31295/adding-custom-ssl-certs-sni">Adding More SSL Certificates (SNI)</xref>
</li>
<li>
<xref type="section" href="#topic31295/ca-certificate-chaining">CA Certificate Chaining</xref>
</li>
<li>
<xref type="section" href="#topic31295/cipher">Customizing the Cipher Suites</xref>
</li>
<li>
<xref type="section" href="#topic31295/generating-a-self-signed-ssl-certificate">Generating a self-signed SSL certificate</xref>
</li>
<li>
<xref type="section" href="#topic31295/using-your-own-ssl-certificate">Replacing the Default SSL Certificate</xref>
</li>
</ul>
</li>
<li>
<xref type="section" href="#topic31295/quota-definitions">Quota Definitions</xref>

<ul>
<li>
<xref type="section" href="#topic31295/sudo">sudo</xref>
</li>
<li>
<xref type="section" href="#topic31295/allowed-repositories">Allowed Repositories</xref>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<section id="changing-the-password"> <title>Changing the Password</title>
<p>The default password for the Helion system user is <b>helion</b>.  In clusters created by Helion Orchestration tools (the Horizon Management Console and Installer CLI VM), access after cluster setup is only available by SSH key pair.</p>
<p>This password is changed to match the one set for the first administrative user created in the Management Console. Once you've set up the primary Application Lifecycle Service admin account, use that account's password when logging in to the VM at the command line.</p>
<p>In an Application Lifecycle Service cluster, this change only happens on the node serving the Management Console pages (which could be one of <xref href="../../../../devplatform/helion/admin/cluster/1.1index.dita#cluster-multi-controllers" type="section"  >multiple Controller nodes</xref>). In this case, it's best to log in to each node in the cluster to change the password
manually with the <i>passwd</i> command.</p>
</section>
<section id="network-setup"> <title>Network Setup</title>
</section>
<section id="changing-the-hostname"> <title>Changing the Hostname</title>
<p>You may want or need to change the hostname of the Application Lifecycle Service system, either to match a DNS record you've created or just to make the system URLs more convenient. This can be done using the <xref href="../../../../devplatform/helion/admin/reference/1.1kato-ref.dita#kato-command-ref" type="section"  >kato node rename</xref> command:</p>
<codeblock>
  <codeph>kato node rename mynewname.example.com
</codeph>
</codeblock>
<p>This command will change the system hostname in <i>/etc/hostname</i> and <i>/etc/hosts,</i> as well as performing some internal configuration for Application Lifecycle Service such as generating a new server certificate for the <xref href="../../../../devplatform/helion/user/console/1.1index.dita#management-console" type="section"  >Management Console</xref>.</p>
<p>mDNS is only supported with ".local" hostnames. If you want to give the
VM a canonical hostname on an existing network, <xref type="section" href="#topic31295/server-config-dns">configure DNS</xref> and disable the <b>mdns</b> role:</p>
<codeblock>
  <codeph>kato role remove mdns
</codeph>
</codeblock>
<p>
<b>Note</b>: Application Lifecycle Service takes a while to configure itself at boot (longer at first boot). Check <i>kato status</i> to see that core services are running before
executing <i>kato node rename</i>.</p>
<p>In a <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-cluster" type="section"  >cluster</xref>, you
may also need to manually <xref type="section" href="#topic31295/server-config-etc-hosts">modify the <i>/etc/hosts file</i>
</xref>.</p>
</section>
<section id="changing-ip-addresses"> <title>Changing IP Addresses</title>
<p>The Application Lifecycle Service <i>micro cloud</i> server is initially set up for <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-dhcp" >DHCP</xref> and <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-multicast-dns" type="section"  >multicast DNS</xref>. This is
often sufficient for local testing, but in this configuration has only a
single node and can only be privately routed.</p>
<p>As you move toward production use of the server, further configuration
of IP addresses and hostnames will therefore be required. A production
Application Lifecycle Service server will most likely be a
<xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-cluster" type="section"  >cluster</xref> consisting
of several nodes and some of them will require IP addresses and corresponding hostnames.</p>
<p>If your server is to be exposed to the Internet, these addresses must be
routable and the hostnames must appear in the global DNS. Even if your
server is to be part of a <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-private-paas" type="section"  >
<i>private
PaaS</i>
</xref> for
organizational use only, it must still integrate fully with your network
services, DHCP and DNS in particular. Finally, in the rare case that
such services are not available, the Application Lifecycle Service can be configured with static IP addresses and hostnames.</p>
<p>Before we examine these scenarios in detail, let's review the separation
of roles in a <xref href="../../../../devplatform/helion/admin/cluster/1.1index.dita#cluster-setup" type="section"  >cluster</xref>:</p>
<ul>
<li>The <b>core</b> node which we conventionally call <codeph>api.helion-xxxx.local</codeph> in a micro cloud will be given its own hostname and IP address in a cluster so that you can reach it from both the <xref href="../../../../devplatform/helion/user/console/1.1index.dita#management-console" type="section"  >Management Console</xref> and the command line.</li>
<li>At the same time, the other nodes in the cluster will also need to reach the core node, so whatever address is configured on its network interface will have to be known to the network, the primary node, and all the other nodes. This can be the same as the primary address assigned to the core, or a secondary address used purely within the cluster.</li>
<li>The <b>router</b> nodes, if separate from the primary, will each require IP addresses of their own, reachable from any load balancer and through any firewall that you put in front of them.</li>
</ul>
<p>Where you configure these hostnames and IP addresses will depend on how
you operate your data center network. You will want to confer with your
network administrator about this, starting with the MAC address
configured for each VM in the hypervisor. If your site supports a
significant number of VMs, DHCP may be set up to map MAC addresses to IP
addresses in a particular way. For example, a certain range of MAC
addresses may be used for servers in the DMZ, and another range for
internal servers. If you follow this convention, your Application Lifecycle Service server
will obtain an appropriate IP address automatically. DNS at your site
may establish a similar convention, which you will want to follow when
making any name or address changes within the cluster.</p>
<p>Having determined the hostnames of cluster nodes to be managed by
<xref type="section" href="#topic31295/server-config-dns">
<i>DNS</i>
</xref>, the hostname on the primary node should be
set using <xref type="section" href="#topic31295/server-config-hostname">
<i>kato node rename</i>
</xref>.</p>
<p>Finally, if you must set a static IP on any cluster node, be sure to
test it before making the change permanent, otherwise you may not be
able to reach the node once it reboots. Assuming that the primary
address is on interface <codeph>eth0</codeph>, a secondary address
<codeph>10.0.0.1/24</codeph> could be set up temporarily as
follows:</p>
<codeblock>
  <codeph>ipcalc -nb 10.0.0.1/24
Address:   10.0.0.1
Netmask:   255.255.255.0 = 24
Wildcard:  0.0.0.255
=&gt;
Network:   10.0.0.0/24
HostMin:   10.0.0.1
HostMax:   10.0.0.254
Broadcast: 10.0.0.255
Hosts/Net: 254                   Class A, Private Internet
sudo ifconfig eth0:1 10.0.0.1 netmask 255.255.255.0 broadcast 10.0.0.255 up
</codeph>
</codeblock>
<p>Configure another cluster node using a different address on the same
subnet, and be sure that <codeph>ping</codeph> works correctly on
the new addresses. You should also use this opportunity to ping the
router and DNS server for this subnet. Check with your network
administrator for their addresses.</p>
</section>
<section id="setting-a-static-ip"> <title>Setting a Static IP</title>
<p>The easiest way to configure an Application Lifecycle Service VM with a static IP address is to use the <xref href="../../../../devplatform/helion/admin/reference/1.1kato-ref.dita#kato-command-ref-op" type="section"  >kato op static_ip</xref> command.</p>
<p>This command will prompt for the following inputs:</p>
<ul>
<li>static IP address (e.g. 10.0.0.1)</li>
<li>netmask (e.g. 255.255.255.0)</li>
<li>network gateway (e.g. 10.0.0.254)</li>
<li>(optional) comma-separated list of DNS names servers (e.g.
10.0.0.252, 10.0.0.253)</li>
<li>(optional) comma-separated list of DNS search domains (e.g.
example.com, example.org)</li>
</ul>
<p>
<codeph>kato</codeph> will verify the IP addresses given are within legal ranges,
automatically calculate the network / broadcast addresses for you, and
prompt for the <i>sudo</i> password to write the changes.</p>
<p>The command can be run non-interactively with the following arguments:</p>
<ul>
<li>--interface</li>
<li>--ip</li>
<li>--netmask</li>
<li>--gateway</li>
<li>--dns-nameservers (set empty "" to skip)</li>
<li>--dns-search-domains (set empty "" to skip)</li>
<li>--restart-network</li>
</ul>
<p>If the IP address provided differs from the previous one, and the node isn't configured as a micro cloud, <xref href="../../../../devplatform/helion/admin/reference/1.1kato-ref.dita#kato-command-ref-node-migrate" type="section"  >kato node migrate</xref> is run automatically.</p>
<p>As a precaution, the command does not automatically restart networking
services. To do so, run the following commands:</p>
<codeblock>
  <codeph>sudo /etc/init.d/networking restart
</codeph>
</codeblock>
<p>You will see a deprecation warning about the <codeph>restart</codeph> option, which can safely be ignored in this context.</p>
<p>
<b>Note</b>
If you are setting a new static IP <i>after</i> having configured a cluster, you must reconfigure all other nodes in the cluster to use the new MBUS IP address. Run <xref href="../../../../devplatform/helion/admin/reference/1.1kato-ref.dita#kato-command-ref-node-attach" type="section"  >kato node attach</xref> on all non-Core nodes.</p>
<p>Alternatively, these changes could be made by editing the <i>/etc/network/interfaces</i> file manually. For example:</p>
<codeblock>
  <codeph>auto eth0
iface eth0 inet static
    address 10.0.0.1
    netmask 255.255.255.0
    network 10.0.0.0
    broadcast 10.0.0.255
    gateway 10.0.0.254
    dns-nameservers 10.0.0.252, 10.0.0.253
    dns-search example.com, example.org
</codeph>
</codeblock>
<p>When DHCP is not used, DNS server IP addresses must be set explicitly
using the <codeph>dns-nameservers</codeph> directive as shown
above. Multiple DNS servers can be specified in a comma separated list.</p>
<p>
<b>Note</b> that <codeph>dnsmasq</codeph> does not necessarily
reinitialize on <codeph>SIGHUP</codeph>. Therefore, perform the
following to reinitialize:</p>
<codeblock>
  <codeph>sudo /etc/init.d/dnsmasq restart
sudo /etc/init.d/networking restart
</codeph>
</codeblock>
<p>Or use <codeph>sudo shutdown -r</codeph> to exercise a complete
restart. Then use <codeph>ifconfig</codeph> to check that the
interface has been configured, and <codeph>ping</codeph> to check
routing to other hosts on the subnet and out in the world. Finally, use
<codeph>dig@&lt;DNS SERVER IP&gt; &lt;HOSTNAME&gt;</codeph> to check that DNS
is resolving correctly.</p>
<p>In the event of troubleshooting, you can confirm which DNS servers are
being used by dnsmasq by checking the file
<i>/var/run/dnsmasq/resolv.conf</i>.</p>
<p>
  <b>Note</b>
</p>
<p>There may be a performance advantage in locally defining a private
secondary IP address (<xref href="http://tools.ietf.org/html/rfc1918" scope="external" format="html" >RFC 1918</xref>) for the controller so
that the other nodes can be assured of routing directly to it. See your
network administrator for advice on which addresses and subnets are
permissible. Once you have this secondary address set up, see the
<xref type="section" href="#topic31295/server-config-etc-hosts">
<i>/etc/hosts</i>
</xref> section for final configuration
of the server.</p>
</section>
<section id="modifying-etc-hosts"> <title>Modifying /etc/hosts</title>
<p>The <codeph>/etc/hosts</codeph> file is used to resolve certain
essential or local hostnames without calling upon the DNS. Unless you
need to <xref type="section" href="#topic31295/server-config-hostname">change the local hostname</xref>, you will
in general <i>not</i> have to edit <codeph>/etc/hosts</codeph> manually,
but when troubleshooting network issues it never hurts to verify that
the file is configured correctly.</p>
<p>As well, various components in a
<xref href="../../../../devplatform/helion/admin/cluster/1.1index.dita#cluster-setup" type="section"  >Cluster</xref> rely on finding the
cluster nodes in <codeph>/etc/hosts</codeph>: the Cloud Controller
and the RabbitMQ service in particular.</p>
<p>Application Lifecycle Service will automatically configure <codeph>/etc/hosts</codeph>
on the virtual machine with one entry for the <codeph>localhost</codeph> loopback address and another for the <xref href="http://tools.ietf.org/html/rfc1918" scope="external" format="html" >RFC 1918</xref> private IP address of
the cluster's Primary node, for example "10.0.0.1" or "192.168.0.1". All
communication between cluster nodes should be strictly through their
private IP addresses and not on routable addresses provided by the DNS.</p>
<p>Remember that <codeph>/etc/hosts</codeph> does not support
wildcards. You must use some form of <xref type="section" href="#topic31295/server-config-dns">DNS</xref> for
that.</p>
<p>Consider an Application Lifecycle Service instance called <codeph>helion-test</codeph>
in domain <codeph>example.com</codeph>. The following example is
what you should expect to see on a <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-micro-cloud" type="section"  >micro cloud</xref>
installation, where all roles are running on the same node:</p>
<codeblock>
  <codeph>hostname
helion-test
ifconfig eth0
eth0      Link encap:Ethernet  HWaddr 08:00:27:fc:1c:f6
  inet addr:10.0.0.1  Bcast:10.0.0.255  Mask:255.255.255.0
  inet6 addr: fe80::a00:27ff:fefc:1cf6/64 Scope:Link
  UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
  RX packets:875142 errors:0 dropped:0 overruns:0 frame:0
  TX packets:106777 errors:0 dropped:0 overruns:0 carrier:0
  collisions:0 txqueuelen:1000
  RX bytes:191340039 (191.3 MB)  TX bytes:23737389 (23.7 MB)
cat /etc/hosts
127.0.0.1       localhost helion-test
10.0.0.1        helion-test.example.com api.helion-test.example.com
</codeph>
</codeblock>
<p>On a <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-cluster" type="section"  >cluster</xref>
installation, the IP address in /etc/hosts will identify the node
hosting the MBUS, usually the same as the Cloud Controller. On this
node, you will see a correspondence between the network interface
<codeph>eth0</codeph> address and <codeph>/etc/hosts</codeph>
as in the above example. On each of the <b>other</b> nodes in the cluster,
for example DEA nodes, <codeph>eth0</codeph> will be configured
with its own address on the same subnet, but <codeph>/etc/hosts</codeph> will remain the same..</p>
<p>If modifying <codeph>/etc/hosts</codeph> becomes necessary because
of a hostname change, you can simply edit it as in the following
example:</p>
<codeblock>
  <codeph>sudo vi /etc/hosts
</codeph>
</codeblock>
</section>
<section id="server-config-dns"> <title>DNS</title>
<p>The Application Lifecycle Service micro cloud uses <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-multicast-dns" type="section"  >multicast DNS</xref> to broadcast its generated hostname (e.g. <codeph>helion-xxxx.local</codeph>). This mechanism is intended for VMs running on a local machine or subnet.</p>
<p>For production use, the server will need:</p>
<ul>
<li>a public DNS record,</li>
<li>a wildcard CNAME record, and</li>
<li>a fixed IP address.</li>
</ul>
<p>For example, a DNS zone file for "helion.example.com" might contain:</p>
<codeblock>
  <codeph>helion.example.com        IN    A        10.3.30.200
*.helion.example.com      IN    CNAME    helion.example.com
</codeph>
</codeblock>
<p>The wildcard CNAME record enables routing for the hostnames created for
each application pushed to Application Lifecycle Service. If your networking policy forbids
the use of wildcard records, you will need to add DNS records for each
application pushed to Application Lifecycle Service as well as the following two hostnames:</p>
<ul>
<li>
<b>api.</b> - API endpoint for clients and the URL of the Management
Console (e.g. api.helion.example.com)</li>
<li>
<b>aok.</b> - AOK authentication endpoint (e.g.
aok.helion.example.com)</li>
</ul>
<p>If you intend to expose your applications at URLs on other domains (e.g.
using <xref href="../../../../devplatform/helion/user/reference/1.1client-ref.dita#command-map" type="section"  >helion map</xref> add these names
to the DNS zone file as well. For example:</p>
<codeblock>
  <codeph>app.domain.com              IN    CNAME    helion.example.com
</codeph>
</codeblock>
<p>Firewalls and load balancers may require corresponding adjustments.</p>
<p>
  <b>Note</b>
</p>
<p>If your site uses DHCP, configure a static binding to the MAC address of
the Application Lifecycle Service VM (and be careful not to change the MAC address
accidentally through the hypervisor). If Application Lifecycle Service is hosted on a cloud
provider, assign a fixed IP address using the platform's tools (e.g.
Floating IP on <tm tmtype="reg">OpenStack</tm></p>
<p>With DNS records in place, the multicast DNS broadcast is no longer
necessary. To turn it off on the Application Lifecycle Service server, use the command:</p>
<codeblock>
  <codeph>kato role remove mdns
</codeph>
</codeblock>
</section>
<section id="dynamic-dns"> <title>Dynamic DNS</title>
<p>If you don't have access to a DNS server, you can use a dynamic DNS
provider, such as <xref href="http://www.changeip.com/" scope="external" format="html" >ChangeIP</xref>
and
<xref href="https://help.ubuntu.com/community/DynamicDNS#Registering_with_a_Dynamic_DNS_provider" type="section" scope="external" format="html" >others</xref>,
to provide DNS records. You will need one that provides wildcard
subdomain assignment.</p>
<p>Before registering your domain, be sure that your mail server will
accept email from the provider (for example
<codeph>support@changeip.com</codeph>).</p>
<p>Create an account, choose a subdomain, and ensure that a wildcard
assignment is made on the subdomain to handle <codeph>api</codeph>
and related application subdomains. Then wait to receive the
authorization email, and verify the zone transfer before proceeding.</p>
</section>
<section id="alternate-dns-techniques-alternate-dns-techniques"> <title>Alternate DNS Techniques {#alternate-dns-techniques)</title>
<p>For situations where mDNS will not work (e.g. running in a cloud hosting
environment or connecting from a Windows system without mDNS support)
but which do not merit the effort of manually configuring a DNS record
(e.g. a test server) alternative methods are available.</p>
</section>
<section id="xip-io"> <title>xip.io</title>
<p>The quickest way to get wildcard DNS resolution is to use the
<xref href="http://xip.io/" scope="external" format="html" >xip.io</xref> service.  This is the approach taken on clusters created with the Horizon Management Console panel or Application Lifecycle Service Installer CLI, and is done as part of the setup process.</p>
<p>
<xref type="section" href="#topic31295/server-config-hostname">Change your hostname</xref> using <xref href="../../../../devplatform/helion/admin/reference/1.1kato-ref.dita#kato-command-ref-node-attach" type="section"  >kato node
rename</xref> to
match the external IP address with the 'xip.io' domain appended. For
example:</p>
<codeblock>
  <codeph>kato node rename 10.9.8.7.xip.io
</codeph>
</codeblock>
<p>This will change the system hostname and reconfigure some internal
Application Lifecycle Service settings. The xip.io DNS servers will resolve the domain
'10.9.8.7.xip.io' and all sub-domains to '10.9.8.7'. This works for
private subnets as well as public IP addresses.</p>
</section>
<section id="dnsmasq"> <title>dnsmasq</title>
<p>Locally, you can run
<xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-dnsmasq" type="section"  >dnsmasq</xref> as a simple
DNS proxy which resolves wildcards for
<codeph>*.helion-test.example.com</codeph> to
<codeph>10.9.8.7</codeph> when line such as the following is
present in any of its configuration files:</p>
<codeblock>
  <codeph>address = /.helion-test.example.com/ 10.9.8.7
</codeph>
</codeblock>
<p>You must restart the service to pick up the changed configuration:</p>
<codeblock>
  <codeph>/etc/init.d/dnsmasq restart
</codeph>
</codeblock>
</section>
<section id="adding-dns-nameservers"> <title>Adding DNS Nameservers</title>
<p>You may need to add site-specific DNS nameservers manually if the
Application Lifecycle Service VM or applications running in Application Lifecycle Service containers need to
resolve internal hosts using a particular nameserver.</p>
<p>To explicitly add a DNS nameserver to an Application Lifecycle Service VM running under DHCP,
edit <i>/etc/dhcp/dhclient.conf</i> and add a line with the DNS server IP.
For example:</p>
<codeblock>
  <codeph>append domain-name-servers 10.8.8.8;
</codeph>
</codeblock>
<p>Reboot to apply the changes.</p>
<p>For Application Lifecycle Service VMs with a static IP, add the nameservers when prompted
when running the <codeph>kato op static_ip</codeph> command (see
<xref type="section" href="#topic31295/server-config-static-ip">Setting a Static IP</xref> above).</p>
</section>
<section id="tcp-udp-port-configuration"> <title>TCP/UDP Port Configuration</title>
<p>The Application Lifecycle Service <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-micro-cloud" type="section"  >micro cloud</xref> runs with
the following ports exposed:</p>
<table>
<tgroup cols="3">
<colspec colname="col1"/>
<colspec colname="col2"/>
<colspec colname="col3"/>
<tbody>
<row>
    <entry>Port</entry>
    <entry>Type</entry>
    <entry>Service</entry>
  </row>
<row>
    <entry>22</entry>
    <entry>tcp</entry>
    <entry>ssh</entry>
  </row>
<row>
    <entry>25</entry>
    <entry>tcp</entry>
    <entry>smtp</entry>
  </row>
<row>
    <entry>80</entry>
    <entry>tcp</entry>
    <entry>http</entry>
  </row>
</tbody>
</tgroup>
</table>
<p>On a production cluster, or a micro cloud running on a cloud hosting
provider, only ports 22 (SSH), 80 (HTTPS) and 443 (HTTPS) need to be
exposed externally (e.g. for the Router / Core node).</p>
<p>Within the cluster (i.e. behind the firewall), it is advisable to allow
communication between the cluster nodes on all ports. This can be done
safely by using the security group / security policy tools provided by
your hypervisor.</p>
<p>If you wish to restrict ports between some nodes (e.g. if you do not
have the option to use security groups), the following summary describes
which ports are used by which components. <b>Source</b> nodes initiate the
communication, <b>Destination</b> nodes need to listen on the specified
port.</p>
<table>
<tgroup cols="5">
<colspec colname="col1"/>
<colspec colname="col2"/>
<colspec colname="col3"/>
<colspec colname="col4"/>
<colspec colname="col5"/>
<tbody>
<row>
    <entry>Port Range</entry>
    <entry>Type</entry>
    <entry>Source</entry>
    <entry>Destination</entry>
    <entry>Required By</entry>
  </row>
<row>
    <entry>22</entry>
    <entry>tcp</entry>
    <entry>all nodes</entry>
    <entry>all nodes</entry>
    <entry>ssh/scp/sshfs</entry>
  </row>
<row>
    <entry>4222</entry>
    <entry>tcp</entry>
    <entry>all nodes</entry>
    <entry>all nodes</entry>
    <entry>dea,controller</entry>
  </row>
<row>
    <entry>3306</entry>
    <entry>tcp</entry>
    <entry>dea,controller</entry>
    <entry>mysql nodes</entry>
    <entry>MySQL</entry>
  </row>
<row>
    <entry>5432</entry>
    <entry>tcp</entry>
    <entry>all nodes</entry>
    <entry>postgresql nodes</entry>
    <entry>PostgreSQL</entry>
  </row>
<row>
    <entry>5454</entry>
    <entry>tcp</entry>
    <entry>all nodes</entry>
    <entry>controller</entry>
    <entry>redis</entry>
  </row>
</tbody>
</tgroup>
</table>
<p>More on  <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-nats" type="section"  >NATS</xref> communication
    with the MBUS IP (core Cloud Controller)10 is available in the glossary.</p>
<p>Each node can be internally firewalled using
<xref href="http://manpages.ubuntu.com/manpages/utopic/en/man8/iptables.8.html" scope="external" format="html" >iptables</xref> to
apply the above rules.</p>
<p>Comments:</p>
<ul>
<li>Ports 80 and 443 need only be open to the world on router nodes.</li>
<li>Port 4222 should be open on all nodes for
<xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-nats" type="section"  >NATS</xref> communication
with the MBUS IP (core Cloud Controller)</li>
<li>Port 9022 should be open to allow transfer of droplets to and from
the DEAs, and Cloud Controllers.</li>
<li>Port 7845 is required if you plan to stream logs from all nodes in a
cluster using <codeph>kato log tail</codeph> command.</li>
<li>External access on port 22 can be restricted if necessary to the
subnet you expect to connect from. If you are providing the
<codeph>helion ssh</codeph> feature to your users
(recommended), define a distinct security group for the
public-facing Cloud Controller node that is the same as a generic
Application Lifecycle Service group, but has the additional policy of allowing SSH (Port
22) from hosts external to the cluster.</li>
<li>Within the cluster, port 22 should be open on all hosts to allow
administrative access over SSH. Port 22 is also used to mount
Filesystem service partitions in application containers on the DEA
nodes (via SSHFS).</li>
<li>The optional Harbor port service has a configurable port range
(default 41000 - 61000) which can be exposed externally if required.</li>
</ul>
</section>
<section id="http-proxy"> <title>HTTP Proxy</title>
<p>
  <b>Note</b>
</p>
<p>If your network has an HTTP proxy, the Helion client may attempt to
use this when connecting to api.helion-xxxx.local and fail because the
changes in <codeph>/etc/hosts</codeph> file are not reflected in
the proxy. To work around this problem in Windows, enable
<codeph>\*.local</codeph> in the <codeph>ProxyOverride</codeph> registry key
<codeph>HCU/Software/Microsoft/Windows/CurrentVersion/Internet Settings</codeph>.</p>
<p>In some cases, it may be a requirement that any HTTP request is first
handled through an upstream or parent proxy (HTTP requests may not be
directly routable otherwise).</p>
<p>In this case it is necessary to tell <xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-polipo" type="section"  >Polipo</xref> about the proxy so it knows how to handle this correctly.</p>
<p>Open the Polipo config file <codeph>/etc/polipo/config</codeph> and
add the lines:</p>
<codeblock>
  <codeph>parentProxy = &lt;IP&gt;:&lt;PORT&gt;
parentAuthCredentials = "myuser:mypassw"
</codeph>
</codeblock>
<p>Then restart Polipo:</p>
<codeblock>
  <codeph>sudo /etc/init.d/polipo restart
</codeph>
</codeblock>
<p>If you are using a SOCKS proxy, edit the file in the same way but with
the lines:</p>
<codeblock>
  <codeph>socksParentProxy=&lt;IP&gt;:&lt;PORT&gt;
socksProxyType=socks4a | OR | socks5;
</codeph>
</codeblock>
<p>Then restart Polipo on each DEA:</p>
<codeblock>
  <codeph>sudo /etc/init.d/polipo restart
</codeph>
</codeblock>
<p>For log info, any errors reported by Polipo are available on the
Application Lifecycle Service server in <codeph>/var/log/polipo/polipo.log</codeph>.</p>
</section>
<section id="staging-cache-app-http-proxy"> <title>Staging Cache &amp; App HTTP Proxy</title>
<p>Application Lifecycle Service caches all application dependencies that are downloaded by module managers that support the <xref href="../../../../devplatform/helion/user/reference/1.1environment.dita#term-http-proxy" type="section"  >HTTP_PROXY</xref> environment variable (e.g. pip, PyPM, PPM, NPM, etc). This is limited to 100MB of in-memory cache.</p>
<p>If you have an upstream HTTP proxy that deployed applications and the
staging system need to traverse to access the internet, use the
<codeph>kato op upstream_proxy ...</codeph> command on all DEA
nodes:</p>
<codeblock>
  <codeph>kato op upstream_proxy set 192.168.0.99:3128
</codeph>
</codeblock>
<p>To remove the proxy setting:</p>
<codeblock>
  <codeph>kato op upstream_proxy delete
</codeph>
</codeblock>
<p>To set an HTTP proxy exclusively for apps, add an <b>environment\app_http_proxy</b> setting in the dea_ng
config using <xref href="../../../../devplatform/helion/admin/reference/1.1kato-ref.dita#kato-command-ref-config" type="section"  >kato config set</xref>. For example:</p>
<codeblock>
  <codeph>kato config set dea_ng environment/app_http_proxy 10.0.0.47:3000
</codeph>
</codeblock>
<p>Adding this configuration sets the 'http_proxy' environment variable
within all subsequently created application containers.</p>
<p>Add the <i>--no-proxy</i> option to bypass the proxy when accessing certain (normally internal) domains. For example:</p>
<codeblock>
  <codeph>kato op upstream_proxy set 192.168.0.99:3128 --no-proxy internal.example.net 
</codeph>
</codeblock>
</section>
<section id="vm-filesystem-setup-vm-filesystem-setup"> <title>VM Filesystem Setup {#vm-filesystem-setup)</title>
<p>The Application Lifecycle Service VM is distributed with a simple default partitioning scheme
(i.e. everything but "/boot" mounted on "/").</p>
<note type="warning">When setting up a production cluster, additional filesystem configuration is necessary to prevent certain nodes from running out of
disk space.</note>
<p>Some nodes in a production cluster may require additional mount points
on external block storage for:</p>
<ul>
<li>services (data and filesystem service nodes)</li>
<li>droplets (controller nodes)</li>
<li>containers (DEA and Stager nodes)</li>
</ul>
<p>Suggestions for mounting block storage and instructions for relocating
data can be found in the <xref href="../../../../devplatform/helion/admin/best-practices/1.1index.dita#bestpractices-persistent-storage" type="section"  >Persistent Storage</xref>
section.</p>
</section>
<section id="helion-data-services-vs-high-availability-databases"> <title>Application Lifecycle Service Data Services vs. High Availability Databases</title>
<p>Application Lifecycle Service data services do not offer any built-in redundancy. For
business-critical data storage, a high-availability database or cluster
is recommended.</p>
<p>To use an external database instead of the data services provided by
Application Lifecycle Service, specify the database credentials directly in your application
code instead of using the credentials from the
<xref href="../../../../devplatform/helion/user/reference/1.1environment.dita#term-vcap-services" type="section"  >VCAP_SERVICES</xref>
environment variable.</p>
<p>To tie external databases to Application Lifecycle Service as a data service, see the
examples in the <xref href="../../../../devplatform/helion/admin/reference/1.1add-service.dita#add-service" type="section"  >Adding System
Services</xref> section.</p>
</section>
<section id="https-ssl"> <title>HTTPS &amp; SSL</title>
<p>HTTPS mode provides access to the provisioned apps using wild card SSL
certificates through the router or
<xref href="../../../../devplatform/helion/user/reference/1.1glossary.dita#term-nginx" type="section"  >Nginx</xref> web server.</p>
<p>The ALS VM generates self-signed wildcard SSL certificates to match the unique <codeph>.local</codeph> hostname it assigns itself at first boot. These certificates can be found in:</p>
<ul>
<li>
<codeph>/etc/ssl/certs/helion.crt</codeph> (Public Certificate)</li>
<li>
<codeph>/etc/ssl/private/helion.key</codeph> (Used to generate the signed certificates)</li>
</ul>
<p>Since these certificates are self-signed, rather than issued by a certificate authority (CA), web browsers will warn that the certificate cannot be verified and prompt the user to add a manual exception.</p>
<p>To avoid this, the generated certificate for the base URL of the PaaS can be replaced with a signed certificate issued by a CA.</p>
<p>For additional Org-owned and Shared domains, SSL certificates can be added using the SNI method described further below.</p>
</section>
<section id="using-your-own-ssl-certificate"> <title>Replacing the Default SSL Certificate</title>
<p>On all router and controller nodes, upload your <i>.key</i> file to the <i>/etc/ssl/private/</i> directory and your <i>.crt</i> file to <i>/etc/ssl/certs/</i>.</p>
<p>Change the following settings with <i>kato config</i> to point to the new files:</p>
<codeblock>
  <codeph>"sslKeyFile": "/etc/ssl/private/example.key",
"sslCertFile": "/etc/ssl/certs/example.crt",
</codeph>
</codeblock>
<p>If you are using a signed certificate and wish to enable strict SSL checking on the internal REST interface (used for communication between the web console and controller), run the following additional command:</p>
<codeblock>
  <codeph>kato config set stackato_rest ssl/strict_ssl true 
</codeph>
</codeblock>
</section>
<section id="adding-custom-ssl-certs-sni"> <title>Adding More SSL Certs (SNI)</title>
<p>The Application Lifecycle Service router supports
<xref href="http://en.wikipedia.org/wiki/Server_Name_Indication" scope="external" format="html" >SNI</xref>, and custom
SSL certificates for domains resolving to the system can be added using
the <xref href="../../../../devplatform/helion/admin/reference/1.1kato-ref.dita#kato-command-ref-op" type="section"  >kato op custom_ssl_cert
install</xref> command.
Usage:</p>
<codeblock>
  <codeph>kato op custom_ssl_cert install &lt;key-path&gt; &lt;cert-path&gt; &lt;domain&gt; [--wildcard-subdomains]
</codeph>
</codeblock>
<p>This must be run on all router nodes in a cluster: the first one as
above, subsequent routers using the <codeph>--update</codeph> flag.</p>
<p>
  <b>Note</b>
</p>
<p>SNI support with multiple Application Lifecycle Service routers works only with TCP load
balancers (e.g. HAProxy, iptables, F5) not HTTP load balancers (e.g.
Nginx, Application Lifecycle Service load balancer).</p>
</section>
<section id="ca-certificate-chaining"> <title>CA Certificate Chaining</title>
<p>When using a signed certificate for Application Lifecycle Service, the certificates in the
chain must be concatenated in a specific order:</p>
<ul>
<li>the domain's crt file</li>
<li>intermediate certs</li>
<li>the root cert</li>
</ul>
<p>For example, to create the final certificate for the chain in Nginx
format:</p>
<codeblock>
  <codeph>sudo su -c "cat /etc/ssl/certs/site.crt /path/to/intermediate.crt /path/to/rootCA.crt &gt; /etc/ssl/certs/helion.crt"
</codeph>
</codeblock>
<p>Once the cert is chained, restart the router processes:</p>
<codeblock>
  <codeph>kato restart router
</codeph>
</codeblock>
<p>Verify that the full chain is being sent by Nginx using
<codeph>openssl</codeph>. You should see more than one number in
the list. For example:</p>
<codeblock>
  <codeph>openssl s_client -connect api.stacka.to:443
---
Certificate chain
 0 s:/C=CA/ST=British Columbia/L=Vancouver/O=HP Software Inc./OU=Application Lifecycle Service/CN=*.stacka.to
   i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance CA-3
 1 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance CA-3
   i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA
 2 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA
   i:/C=US/O=Entrust.net/OU=www.entrust.net/CPS incorp. by ref. (limits liab.)/OU=(c) 1999 Entrust.net Limited/CN=Entrust.net Secure Server Certification Authority
</codeph>
</codeblock>
</section>
<section id="generating-a-self-signed-ssl-certificate"> <title>Generating a self-signed SSL certificate</title>
<p>You can re-generate Application Lifecycle Service's self-signed SSL certificate by running
the following command on the VM:</p>
<codeblock>
  <codeph>kato op regenerate ssl_cert
</codeph>
</codeblock>
<p>To do essentially the same operation manually (substituting
"hostname.mydomain.com" with your own details):</p>
<codeblock>
  <codeph>mkdir ~/hostname.mydomain.com
cd ~/hostname.mydomain.com
(umask 077 &amp;&amp; touch host.key host.cert host.info)
openssl genrsa 2048 &gt; host.key
openssl req -new -x509 -nodes -sha1 -days 365 -key host.key -multivalue-rdn \
        -subj "/C=CA/emailAddress=email@mydomain.com/O=company_name/CN=*.mydomain.com/CN=mydomain.com" \
        &gt;host.crt
</codeph>
</codeblock>
<p>For specific configurations that can be used in the <codeph>-subj</codeph> option, see  the <xref href="http://www.openssl.org/docs/apps/req.html" scope="external" format="html" >Open SSL</xref> documentation.</p>
<p>Following that, run:</p>
<codeblock>
  <codeph>openssl x509 -noout -fingerprint -text &lt; host.crt &gt; host.info
chmod 400 host.key host.crt
</codeph>
</codeblock>
<p>To get the router to use the new certificate and key files, follow the
steps in the <xref type="section" href="#topic31295/server-config-ssl-cert-own-use">
<i>Using your own SSL
certificate</i>
</xref> section above.</p>
<p>With any self-signed SSL certificate, you will get browser warning
messages. The certificate will need to be added to the browser exception
rules, which you will be prompted to do so when visiting one of your
apps via HTTPS for the first time.</p>
</section>
<section id="cipher"> <title>Customizing the Cipher Suites</title>
<p>The router's TLS cipher suite can be modified using <i>kato config</i>. For example:</p>
<codeblock>
  <codeph>kato config set router2g ssl/cipher_suite 'ALL:!ADH:!EXP:!LOW:!RC2:!3DES:!SEED:!SSLv3:RC4+RSA:+HIGH:+MED'
</codeph>
</codeblock>
<p>The setting above is the default for the Helion router minus SSLv3. See OpenSSL's <xref href="https://www.openssl.org/docs/apps/ciphers.html#CIPHER_LIST_FORMAT" scope="external" format="html" >Cipher List Format</xref> and <xref href="https://www.openssl.org/docs/apps/ciphers.html#CIPHER_STRINGS" type="section" scope="external" format="html" >Cipher Strings</xref> documentation for other valid values.</p>
</section>
<section id="quota-definitions"> <title>Quota Definitions</title>
<p>Quota definitions define limits for:</p>
<ul>
<li>physical memory (RAM) in MB</li>
<li>number of services</li>
<li>
<i>sudo</i> privilege within application containers</li>
</ul>
<p>Each organization is assigned a quota definition, and all users of an
organization share the defined limits.</p>
<p>Use the <i>helion quota ...</i> commands to modify
quota definitions:</p>
<ul>
<li>
<xref href="../../../../devplatform/helion/user/reference/1.1client-ref.dita#command-quota-configure" type="section"  >
<i>helion quota configure</i>
</xref>
</li>
<li>
<xref href="../../../../devplatform/helion/user/reference/1.1client-ref.dita#command-quota-create" type="section"  >
<i>helion quota
create</i>
</xref>
</li>
<li>
<xref href="../../../../devplatform/helion/user/reference/1.1client-ref.dita#command-quota-delete" type="section"  >
<i>helion quota
delete</i>
</xref>
</li>
<li>
<xref href="../../../../devplatform/helion/user/reference/1.1client-ref.dita#command-quota-list" type="section"  >
<i>helion quota
list</i>
</xref>
</li>
</ul>
<p>Existing quota definitions can also be viewed and edited in the
Management Console <xref href="../../../../devplatform/helion/admin/console/1.1customize.dita#console-settings-quota-definitions" type="section"  >Quota Definitions settings</xref>
</p>
</section>
<section id="sudo"> <title>sudo</title>
<p>Quota Definitions can give all users in an Organization the use of the <b>sudo</b> command within application containers. This option is disabled by default as a security precaution, and should only be enabled for Organizations where all users are trusted.</p>
</section>
<section id="allowed-repositories"> <title>Allowed Repositories</title>
<p>Users (with our without <i>sudo</i> permissions) can install Ubuntu packages in application containers by requesting them in the requirements section of an application's <i>manifest.yml</i> file. The system allows package installation only from those repositories specified in the <b>Allowed Repos</b> list in the Management Console.</p>
<p>This list can also be viewed and modified at the command line using <xref href="../../../../devplatform/helion/admin/reference/1.1kato-ref.dita#kato-command-ref-config" type="section"  >kato config</xref>. For example, to view the 
 current list:</p>
<codeblock>
  <codeph>   kato config get cloud_controller_ng allowed_repos 
    - deb mirror://mirrors.ubuntu.com/mirrors.txt precise main restricted universe multiverse 
    - deb mirror://mirrors.ubuntu.com/mirrors.txt precise-updates main restricted universe multiverse 
    - deb http://security.ubuntu.com/ubuntu precise-security main universe 
</codeph>
</codeblock>
<p>To add a repository:</p>
<codeblock>
  <codeph>kato config push cloud_controller_ng allowed_repos 'deb http://apt.newrelic.com/debian/ newrelic non-free' 
    - deb mirror://mirrors.ubuntu.com/mirrors.txt precise main restricted universe multiverse 
    - deb mirror://mirrors.ubuntu.com/mirrors.txt precise-updates main restricted universe multiverse 
    - deb http://security.ubuntu.com/ubuntu precise-security main universe 
    - deb http://apt.newrelic.com/debian/ newrelic non-free 
</codeph>
</codeblock>
<p>Once a repository has been added to the list, <b>the GPG key must also be added</b> to the <xref href="../../../../devplatform/helion/admin/server/1.1docker.dita#modifying-or-updating-the-container-image" >Docker base image</xref> on each DEA (or the <xref href="../../../../devplatform/helion/admin/server/1.1docker.dita#creating-a-docker-registry" type="section"  >Docker registry</xref> server if configured).</p>
<p>For example, to trust the GPG for the New Relic repository, add the following line to the <i>Dockerfile</i> for the base image:</p>
<codeblock>
  <codeph>RUN wget -O- https://download.newrelic.com/548C16BF.gpg | apt-key add -
</codeph>
</codeblock>
</section>
<section id="container_NFS"> <title>Container NFS Mounts</title>
  <note type="warning">Reconfiguring ALS to allow user applications to mount NFS partitions has serious security implications. See the <xref href="../../../../devplatform/helion/admin/server/1.1docker.dita#docker-privileged-containers" type="section"  >Privileged Containers</xref> section for details.</note>
<p>By default, application containers are unable to mount external filesystems (other than the built-in <xref href="../../../../devplatform/helion/user/services/1.1filesystem.dita" >Filesystem Service</xref> via network protocols such as NFS.</p>
<p>If the system has been configured to use <xref href="../../../../devplatform/helion/admin/server/1.1docker.dita#docker-privileged-containers" type="section"  >privileged containers</xref> and <i>sudo</i> permissions have been explicitly allowed in the quota, NFS partitions can be mounted in application containers using application configuration similar to the following manifest.yml excerpt:
requirements:</p>
<codeblock>
  <codeph>  ubuntu:
      - nfs-common
hooks:
  pre-running:
    - mkdir /mount/point
    - sudo mount nfs.server:/path/to/export /mount/point
</codeph>
</codeblock>
<p>The IP address of the NFS server must also be added to the  docker/allowed_supnet_ips  list. For example:</p>
<codeblock>
  <codeph>kato config push fence docker/allowed_subnet_ips 10.0.0.110
</codeph>
</codeblock>
</section>
</body>
</topic>
