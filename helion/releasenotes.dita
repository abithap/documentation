<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" >
<topic xml:lang="en-us" id="topic12031">
  <title>Beta 0: Release Notes</title>
  <body>
    <p>This document provides an overview of the features contained within HP Helion OpenStack 2.0
      Beta 0, including known issues and workarounds, and where to find further information on this
      release:</p>
    <ul>
      <li>Features in HP Helion OpenStack 2.0 Beta 0</li>
      <li>Known Issues in this Release</li>
      <li>For Further Information</li>
    </ul>
    <section id="Features">
      <title>Features in HP Helion OpenStack 2.0</title>
      <p><b>Updated HP Helion OpenStack Services</b> - We have included the core set of OpenStack
        services from the <xref href="https://wiki.openstack.org/wiki/ReleaseNotes/Kilo"
          scope="external" format="html">Kilo release</xref>.</p>
      <p><b>New Neutron Extensions for Detailed Network Architectures</b> - We have implemented new
        networking extensions for load balancing, firewalls, and VPN. Here is a description of each
        of these:</p>
      <ul>
        <li>LBaaS (Load-Balancing-as-a-Service) is a Neutron extension that introduces a load
          balancing feature set. Helion OpenStack 2.0 includes the V2 version which allows
          implementation uses haproxy but 3rd party Load Balancers can be integrated as well. In
          case that a 3rd party driver doesnâ€™t exist for LBaaS V2 installing LBaaS V1 instead of V2
          is supported. <ul>
            <li>For more information, see: <xref
                href="https://wiki.openstack.org/wiki/Neutron/LBaaS" scope="external" format="html"
                >https://wiki.openstack.org/wiki/Neutron/LBaaS</xref></li>
          </ul>
        </li>
        <li>FWaaS (FireWall-as-a-Service) is a Neutron extension that introduces a firewall eature
          set. The included reference implementation is using iptables to block traffic but 3rd
          party Firewalls can be integrated with this extension into Helion OpenStack as well. <ul>
            <li>For more information, see: <xref
                href="https://wiki.openstack.org/wiki/Neutron/FWaaS" scope="external" format="html"
                >https://wiki.openstack.org/wiki/Neutron/FWaaS</xref></li>
          </ul>
        </li>
        <li>VPNaaS (Virtual-Private-Network-as-a-Service) is a Neutron extension that introduces a
          vpn feature set. It allows for encrypted traffic between two routers in (potentially)
          different datacenters hence supporting secure multi Availability Zone architectures for
          customers. <ul>
            <li>For more information, see: <xref
                href="https://wiki.openstack.org/wiki/Neutron/VPNaaS" scope="external" format="html"
                >https://wiki.openstack.org/wiki/Neutron/VPNaaS</xref></li>
          </ul>
        </li>
      </ul>
      <p><b>New Neutron Features for Greater Performance</b> - We have included native support for
        the following features in our Neutron offering:</p>
      <ul>
        <li>NIC bonding with multiple modes will allow you to setup a highly available and
          performant network infrastructure.</li>
        <li>Multi-Network support will allow you to bridge multiple external physical networks to a
          Neutron network. This will enable you to dictate the path taken by the data in the
          physical network outside of your cloud deployment.</li>
        <li>Network separation (both physical and VLAN) will allow you to segregate traffic by type.
          In the cloud today, traffic is separated into management, tenant, external, and services
          channels.</li>
      </ul>
      <p><b>Monasca-based Monitoring with OpsConsole GUI</b> - Monasca is a multi-tenant, scalable,
        fault-tolerant monitoring-as-a-service, HTTP-based service. It uses a REST API for
        high-speed metrics processing and querying, and has a streaming alarm and notification
        engine. There is also a custom-built OpsConsole for GUI access. In the Helion OpenStack 2.0
        release, the OpenStack monitoring standard, Monasca, is supported as the Helion OpenStack
        monitoring solution with the following exceptions (which are not implemented):</p>
      <ul>
        <li>Transform Engine</li>
        <li>Events Engine </li>
        <li>Anomaly and Prediction Engine</li>
      </ul>
      <p><b>New Baremetal Installation Kit</b> - </p>
      <ul>
        <li>You supply the cloud configuration you want based on our <xref
            href="supportedconfigs.dita">Supported Configurations</xref> and the baremetal installer
          will setup your environment.</li>
        <li>Manage the different phases of your cloud deployment with ease</li>
      </ul>
      <!--
  <p><b>Backup and Restore Capabilities for the Control Plane</b> - Allows you to backup and recover your Helion OpenStack environment with RPO=0.</p>
  -->
    </section>
    <section id="KnownIssues"><title>Known Issues in this Release</title><p><b>HP Helion Development
          Platform</b></p><p>Helion Development Platform is not supported on Beta
          0</p><p><b>Installing Swift</b></p><p>Swift installs with the following limitations: </p><ul>
        <li>Only a 3-node Swift configuration in which Swift runs on the 3 controller servers is
          supported</li>
        <li>No LVM (logical volumes) support. Therefore, dedicated disks are needed for Swift on the
          3 controller nodes</li>
        <li>In Beta0 you cannot add or remove Swift servers</li>
        <li>Only one Swift zone is supported</li>
        <li>Support only 1 storage policy, object-0</li>
      </ul><!-- <p>
      <b>Deployment of VSA cloud on a separate Node as per the life-cycle management
      features</b></p>
    <p>Completed activity:</p>
    <p> vsa-deploy play to deploy VSA on standalone node</p>
    <p> cmc-deploy play do deploy CMC on controller node [0] </p>
    <p> one-region-poc-with-vsa file with dev environment </p>
    <p>Impediment:</p>
    <p>The one-region-poc-with-vsa will be provided by the HLM team which impacts not only VSA but
      other services as well. This will be beyond be Beta0 timeframe.</p>
    <p> </p>--><p><b>Health
          and performance monitoring</b></p><p>Monitoring is enabled for several, but not all
        services</p><p>Monitoring is integrated for the following services:</p><p>Logging, Neutron,
        Swift, Ceilometer, Heat, Rabbit, MySQL, HA Proxy, Glance, Cinder, Monitoring of Monasca,
        Nova, hLinux</p><p>The following are yet to be completed:</p><ul>
        <li>OpsConsole</li>
        <li>Keystone</li>
        <li>Horizon</li>
      </ul><p>This list to be updated real time as teams progress</p><p><b>Helion Cloud Monitoring
          (Monasca) via the lifecycle management features</b></p><p>Basic Monitoring is complete for
        Beta0 with the following limitations:</p><ul>
        <li>Vertica is not available in the install. Must choose InfluxDB option instead.</li>
        <li>InfluxDB not configured behind a VIP. Must directly access one node in the cluster.</li>
        <li>Backup/restore of Monasca configuration and metrics data is not available.</li>
      </ul><p><b>Cinder</b></p><p>Core cinder services are all being installed and configured via
        the installer.</p><p>Cinder installation with VSA as a backend is being worked through at
        the moment, manual steps to be defined later may be required to complete
          installation.</p><p><b>Networks</b></p><p>This requirement is primarily network
        configuration that will be done through the installer. There is no upstream neutron work
        required.</p><p>** This is not NIC Bonding**</p><p>Multiple NICs on a compute node and each
        NIC is connected to a different external network. Today we don't support multiple external
        networks at L2 (ML2 OVS mech driver) nor L3 (DVR Or
          Centralized)</p><!--<p>Need use cases/stories </p>
    <p>* ability to span L3</p>
    <p>* multiple provider networks/separation of traffic</p>
    <p>* two pools for fip to span networks/different fip pools</p>
    <p>* talk to multiple networks</p>
    <p> </p>
    <p>[06/02/15]</p>
    <p>We discussed today that all of the use cases should be fulfilled by HOS2.0.</p>
    <p> </p>--><p><b>TLS</b></p><p>The
        server certificate is currently hard coded. If an operator wishes to provide their own, they
        need to edit the defaults in the TLS playbook. <i>The intent is to provide an interface via
          a soft link in the ansible system to do this.</i>status unkown</p><p><b>Known
        Issues</b></p><p><b>Install:</b></p><p>Boot order may be affected by random assignment of
        eth interface numbers to your NICs. Therefore the node you need to boot first may not be
        first. You may want to disable NICs that you are not planning to
          use.</p><p><b>Operations:</b></p><!--<p><b>FAQ</b></p>
    
    <p><b>What level of customisation possible via modifying configurations in the CP and using them
        to deploy?</b></p>
    <p>Aim of beta0 is get additional testing of the POC configuration. </p>
    <p><b>Support for Multiple Provider VLANs as external networks?</b></p>
    <p>This functionality is latent in beta0 but has not yet (9/27) been tested. </p>
    <p><b>Can I add nodes to resource pool?</b></p>
    <p>Possible to add VSA and Compute nodes. Default is 1 of each.</p>
    <p><b>What other settings will we be able to customize in Beta0?</b></p>
    <p>Specifically, will we be able to set things like server affinity through jinja files, or will
      those need to be manual changes? M. Dunnett</p>--><p><b>Ops
          Console</b></p>Not enabled.</section>
  </body>
</topic>