<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_fld_zzy_lt">
  <title>Removing a Compute Node</title>
  <body>
  <section id="removeNodes"> The process for removing a compute node requires that you run these steps: <ol>
        <li>Disable provisioning to prevent new instances from being created on this node.  </li>
        <li>If possible migrate any instances on the node to other nodes. </li>
        <li>Shut down the node or stop the nova-compute service. </li>
        <li>Delete the compute node from nova </li>
        <li>Amend servers.yml in the cloud configuration to remove entry for this node, commit the
          change and re run the config processor </li>
        <li>Remove the node from cobbler</li>
    <li>If you have availability zones configured, follow the <xref
            href="#topic_fld_zzy_lt/removeAZ" format="dita">remove nodes in availability
            zones</xref> steps first.</li>
      </ol> 
    
    <ol>
    <li>For example, using a cloud administrator account first disable provisioning and then run
      nova service-list
      <codeblock>~$ nova service-disable --reason="HNOV-240 - removed" hlm004-ccp-comp0004-mgmt nova-compute
~$ nova service-list</codeblock>
      to see the
      result<codeblock>+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
| Id | Binary           | Host                     | Zone     | Status  | State | Updated_at | Disabled Reason |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
...
| 40 | nova-compute     | hlm004-ccp-comp0005-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 46 | nova-compute     | hlm004-ccp-comp0002-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 49 | nova-compute     | hlm004-ccp-comp0006-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 52 | nova-compute     | hlm004-ccp-comp0003-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 55 | nova-compute     | hlm004-ccp-comp0001-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:56.000000 | -                  |
| 58 | nova-compute     | hlm004-ccp-comp0004-mgmt | nova     | disabled | up    | 2015-09-17T10:29:55.000000 | HNOV-240 - removed |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+</codeblock>
  </li><li>    Next, run<codeblock>~$ nova list --host=hlm004-ccp-comp0004-mgmt --all_tenants=1</codeblock>
      to see all
      tenants<codeblock>+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+
| ID                                   | Name   | Tenant ID                        | Status | Task State | Power State | Networks        |
+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+
| 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9 | paul4d | 5e9998f1b1824ea9a3b06ad142f09ca5 | ACTIVE | -          | Running     | paul=10.10.10.7 |
+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+</codeblock>
    </li><li> Now, perform the
          migration:<codeblock>~$ nova live-migration --block-migrate 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9
~$ nova list --host=hlm004-ccp-comp0004-mgmt --all_tenants=1</codeblock>
          and run nova list (above) to get the
          status:<codeblock>+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+
| ID                                   | Name   | Tenant ID                        | Status    | Task State | Power State | Networks        |
+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+
| 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9 | paul4d | 5e9998f1b1824ea9a3b06ad142f09ca5 | MIGRATING | migrating  | Running     | paul=10.10.10.7 |
+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+</codeblock>
        </li><li> Run nova list again
          <codeblock>~$ nova list --host=hlm004-ccp-comp0004-mgmt --all_tenants=1</codeblock> to see
          that the running instance has been
          migrated:<codeblock>+----+------+-----------+--------+------------+-------------+----------+
| ID | Name | Tenant ID | Status | Task State | Power State | Networks |
+----+------+-----------+--------+------------+-------------+----------+
+----+------+-----------+--------+------------+-------------+----------+</codeblock>
        </li><li> Log into compute node and stop nova service or shutdown node. (alternatively, you may re-image
          the
          node)<codeblock>~$ ssh stack@hlm004-ccp-comp0004-mgmt "sudo systemctl stop nova-compute"</codeblock>
          or to shut it
          down:<codeblock>~$ ssh stack@hlm004-ccp-comp0004-mgmt "sudo shutdown now"</codeblock>Alternatively,
          from the deployer, run the<b>bm-power-down.yml </b>playbook <codeblock>~$ cd ~/helion/hos/ansible
    ~/helion/hos/ansible$ ansible-playbook -i hosts/localhost bm-power-down.yml -e nodelist=cpn-0004</codeblock>
          <codeblock>PLAY [localhost] **************************************************************
    GATHERING FACTS *************************************************************** 
    ok: [localhost]
    TASK: [cobbler | get-nodelist | User-specified target list] ******************* 
    ok: [localhost]
    TASK: [cobbler | get-nodelist | Check we have targets] ************************ 
    skipping: [localhost]
    TASK: [debug var=target_nodes] ************************************************ 
    ok: [localhost] => {
    "var": {
    "target_nodes": [
    "cpn-0004"
    ]
    }
    }
    TASK: [cobbler | power-down | Power the nodes down] *************************** 
    changed: [localhost] => (item=cpn-0004)
    PLAY RECAP ******************************************************************** 
    cobbler | power-down | Power the nodes down ----------------------------- 1.48s
    cobbler | get-nodelist | User-specified target list --------------------- 0.02s
    debug var=target_nodes -------------------------------------------------- 0.01s
    cobbler | get-nodelist | Check we have targets -------------------------- 0.01s
    -------------------------------------------------------------------------------
    Total: ------------------------------------------------------------------ 3.54s
    localhost : ok=4 changed=1 unreachable=0 failed=0</codeblock>
        </li><li>Next, delete the nova compute node:
      <codeblock>~$ nova service-delete 58
~$ nova service-list</codeblock> And run nova
      service-list (above) to see that it s
      gone:<codeblock>+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
| Id | Binary           | Host                     | Zone     | Status  | State | Updated_at | Disabled Reason |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
...
| 40 | nova-compute     | hlm004-ccp-comp0005-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 46 | nova-compute     | hlm004-ccp-comp0002-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 49 | nova-compute     | hlm004-ccp-comp0006-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 52 | nova-compute     | hlm004-ccp-comp0003-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 55 | nova-compute     | hlm004-ccp-comp0001-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:56.000000 | -                  |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+</codeblock>
      </li><li>Then get hypervisor status:<codeblock>~$ nova hypervisor-list</codeblock> And check that the
      node has been removed from the
      list:<codeblock>+----+--------------------------+-------+---------+
| ID | Hypervisor hostname      | State | Status  |
+----+--------------------------+-------+---------+
| 1  | hlm004-ccp-comp0005-mgmt | up    | enabled |
| 7  | hlm004-ccp-comp0002-mgmt | up    | enabled |
| 10 | hlm004-ccp-comp0006-mgmt | up    | enabled |
| 13 | hlm004-ccp-comp0003-mgmt | up    | enabled |
| 16 | hlm004-ccp-comp0001-mgmt | up    | enabled |
+----+--------------------------+-------+---------+</codeblock>
      </li><li>Then, on the deployer node, remove the node from <b>servers.yml </b>, commit the change, and
          rerun the config
          processor:<codeblock>cd ~/helion/my_cloud/definition/data
git checkout site</codeblock>
        </li><li>Edit <b>servers.yml </b>to remove the entry for removed node.
          <codeblock>git commit -a -m "Removed node &lt;name>"
cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock>
        </li><li>There is no need to run the site.yml playbook. However you should remove the node from
      cobbler, as shown
      here:<codeblock>sudo cobbler system remove --name=&lt;node>
ansible-playbook -i hosts/localhost cobbler-deploy.yml</codeblock>
      </li></ol>
    </section>
    
    <section id="removeAZ"><title>Before you remove nodes in availability zones</title> When removing a compute node, if availability zones have been
      configured, either manually or using the Nova playbook nova-cloud-configure.yml or you have
      manually configured any host aggregates, then before executing the the service-delete command
      you need to remove the host(s) being deleted from any host aggregates. For example... 
      <ol>
    <li>Disable the
          service<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova service-disable --reason="HNOV-240 - removed" padawan-ccp-comp0002-mgmt nova-compute</codeblock><codeblock>+---------------------------+--------------+----------+--------------------+
| Host                      | Binary       | Status   | Disabled Reason    |
+---------------------------+--------------+----------+--------------------+
| padawan-ccp-comp0002-mgmt | nova-compute | disabled | HNOV-240 - removed |
+---------------------------+--------------+----------+--------------------+</codeblock></li><li>Get nova service
          list<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova service-list</codeblock><codeblock>+----+------------------+---------------------------+----------+----------+-------+----------------------------+--------------------+
| Id | Binary           | Host                      | Zone     | Status   | State | Updated_at                 | Disabled Reason    |
+----+------------------+---------------------------+----------+----------+-------+----------------------------+--------------------+
| 1  | nova-conductor   | padawan-ccp-c1-m1-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:12.000000 | -                  |
| 4  | nova-scheduler   | padawan-ccp-c1-m1-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:13.000000 | -                  |
| 7  | nova-conductor   | padawan-ccp-c1-m3-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:14.000000 | -                  |
| 10 | nova-conductor   | padawan-ccp-c1-m2-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:12.000000 | -                  |
| 13 | nova-scheduler   | padawan-ccp-c1-m3-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:13.000000 | -                  |
| 16 | nova-consoleauth | padawan-ccp-c1-m1-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:14.000000 | -                  |
| 19 | nova-scheduler   | padawan-ccp-c1-m2-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:13.000000 | -                  |
| 22 | nova-compute     | padawan-ccp-comp0002-mgmt | AZ2      | disabled | up    | 2015-10-12T08:46:12.000000 | HNOV-240 - removed |
| 25 | nova-compute     | padawan-ccp-comp0001-mgmt | AZ1      | enabled  | up    | 2015-10-12T08:46:11.000000 | -                  |
| 28 | nova-compute     | padawan-ccp-comp0003-mgmt | AZ3      | enabled  | up    | 2015-10-12T08:46:11.000000 | -                  |
+----+------------------+---------------------------+----------+----------+-------+----------------------------+--------------------+</codeblock></li><li>Get availability
          zones<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova aggregate-list</codeblock><codeblock>+----+------+-------------------+
| Id | Name | Availability Zone |
+----+------+-------------------+
| 1  | AZ1  | AZ1               |
| 4  | AZ2  | AZ2               |
| 7  | AZ3  | AZ3               |
+----+------+-------------------+</codeblock></li><li>Check that the AZ has been
          ???<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova aggregate-remove-host AZ2 padawan-ccp-comp0002-mgmt</codeblock><codeblock>Host padawan-ccp-comp0002-mgmt has been successfully removed from aggregate 4</codeblock><codeblock>+----+------+-------------------+-------+-------------------------+
| Id | Name | Availability Zone | Hosts | Metadata                |
+----+------+-------------------+-------+-------------------------+
| 4  | AZ2  | AZ2               |       | 'availability_zone=AZ2' |
+----+------+-------------------+-------+-------------------------+</codeblock></li><li>Get Availability Zone aggregate
          details<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova aggregate-details AZ2</codeblock><codeblock>+----+------+-------------------+-------+-------------------------+
| Id | Name | Availability Zone | Hosts | Metadata                |
+----+------+-------------------+-------+-------------------------+
| 4  | AZ2  | AZ2               |       | 'availability_zone=AZ2' |
+----+------+-------------------+-------+-------------------------+</codeblock></li>
      <li>Delete service ID 22 (AZ2) and check that is is deleted using nova
          service-list<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova service-delete 22
stack@padawan-ccp-c0-m1-mgmt:~$ nova service-list</codeblock><codeblock>+----+------------------+---------------------------+----------+---------+-------+----------------------------+-----------------+
| Id | Binary           | Host                      | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+----+------------------+---------------------------+----------+---------+-------+----------------------------+-----------------+
| 1  | nova-conductor   | padawan-ccp-c1-m1-mgmt    | internal | enabled | up    | 2015-10-12T08:47:56.000000 | -               |
| 4  | nova-scheduler   | padawan-ccp-c1-m1-mgmt    | internal | enabled | up    | 2015-10-12T08:47:53.000000 | -               |
| 7  | nova-conductor   | padawan-ccp-c1-m3-mgmt    | internal | enabled | up    | 2015-10-12T08:47:54.000000 | -               |
| 10 | nova-conductor   | padawan-ccp-c1-m2-mgmt    | internal | enabled | up    | 2015-10-12T08:47:52.000000 | -               |
| 13 | nova-scheduler   | padawan-ccp-c1-m3-mgmt    | internal | enabled | up    | 2015-10-12T08:47:53.000000 | -               |
| 16 | nova-consoleauth | padawan-ccp-c1-m1-mgmt    | internal | enabled | up    | 2015-10-12T08:47:54.000000 | -               |
| 19 | nova-scheduler   | padawan-ccp-c1-m2-mgmt    | internal | enabled | up    | 2015-10-12T08:47:53.000000 | -               |
| 25 | nova-compute     | padawan-ccp-comp0001-mgmt | AZ1      | enabled | up    | 2015-10-12T08:47:51.000000 | -               |
| 28 | nova-compute     | padawan-ccp-comp0003-mgmt | AZ3      | enabled | up    | 2015-10-12T08:47:51.000000 | -               |
+----+------------------+---------------------------+----------+---------+-------+----------------------------+-----------------+</codeblock></li>      
      
     <li>Finally, follow the <xref href="#topic_fld_zzy_lt/removeNodes" format="dita">remove node
            steps</xref> at the top of this document. </li> 
      </ol>






    </section>
  </body>
</topic>
