<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="troubleshooting_installation">
  <title>Troubleshooting the Installation</title>
  <body>
    <section id="troubleshooting">
      <title>Troubleshooting Tips</title>
      <p><b>Running the <codeph>hos-init.bash</codeph> script when configuring your deployer does
          not complete</b></p>
      <p>Part of what the <codeph>hos-init.bash</codeph> script does in <xref
          href="bare_installation_kvm.dita#install_kvm/HLM_Node_Personalization">step 3 of
          configuring the Deployer</xref> is install git and so if your DNS nameserver is not
        configured or is not funcionting properly in your <codeph>/etc/resolv.conf</codeph> file of
        your deployer node then it won't be able to complete.</p>
      <p>To resolve this issue, double check your nameserver in your
          <codeph>/etc/resolv.conf</codeph> file on your deployer.</p>
      <p id="reimage"><b>How to re-image an existing node</b></p>
      <p>If you've already run the <codeph>cobbler-deploy.yml</codeph> and
          <codeph>bm-reimage.yml</codeph> playbooks and needed to make a change to your
        configuration files or for any other reason need to re-image one of your nodes, you need to
        notify Cobbler in order to do this. The reason for this is that whenever a node has been
        imaged, Cobbler sets a flag, <codeph>netboot-enabled</codeph>, to false to indicate that
        it's already been installed.</p>
      <p>In order to tell Cobbler that you want to re-image it, you can run these commands: <ol>
          <li>To get a list of your system names, use:
            <codeblock>sudo cobbler system list</codeblock></li>
          <li>Notify Cobbler to set the <codeph>netboot-enabled</codeph> flag to true by using: <codeblock>ansible-playbook -i hosts/localhost cobbler-deploy.yml -e nodelist="&lt;node1>,&lt;node2>..."</codeblock>
            <note>If you need to re-image your nodes, you can add the <codeph>-e
                nodelist=all</codeph> switch to the end of your <codeph>bm-reimage.yml</codeph>
              command.</note></li>
          <li>Then proceed with your <codeph>cobbler-deploy.yml</codeph> and
              <codeph>bm-reimage.yml</codeph> playbooks again.</li>
        </ol>
      </p>
      
      <p id="configproc"><b>Change needed to configuration files after you've run the
        <codeph>config-processor-run.yml</codeph> playbook</b></p>
      <p>If you've run the <codeph>config-processor-run.yml</codeph> playbook during the
        installation and have to go back to re-do your steps, ensure that you run the
        <codeph>config-processor-clean.yml</codeph> playbook to clear out your previous
        configuration before proceeding.</p>
      <p>
        <codeblock>cd ~/helion/hos/ansible
          ansible-playbook -i hosts/localhost config-processor-clean.yml</codeblock>
      </p>
      
      <p><b>Change needed to <codeph>baremetalConfig.yml</codeph> file needed after the Cobbler
          deploy</b></p>
      <p>If you've made a mistake or wish to change your <codeph>baremetalConfig.yml</codeph>
        configuration file after you've already run the <codeph>cobbler-deploy.yml</codeph>
        playbook, follow these steps to ensure Cobbler gets updated with the new server
        information:</p>
      <ol>
        <li>Ensure your <codeph>baremetalConfig.yml</codeph> file is updated</li>
        <li>Commit your changes to git:
          <codeblock>cd ~/helion/hos/ansible
git add -A
git commit -m "My config or other commit message"</codeblock></li>
        <li>Determine which nodes you have entered into Cobbler by using:
          <codeblock>sudo cobbler system list</codeblock></li>
        <li>Remove the nodes that had the old information from Cobbler using:
          <codeblock>sudo cobbler system remove --name &lt;nodename></codeblock></li>
        <li>Re-run the <codeph>cobbler-deploy.yml</codeph> and <codeph>bm-reimage.yml</codeph>
          ansible scripts to upload the new node definitions to Cobbler and image the nodes:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost cobbler-deploy.yml
ansible-playbook -i hosts/localhost bm-reimage.yml</codeblock>
        </li>
      </ol>

      <p><b>If the <codeph>site.yml</codeph> playbook fails, you can query the log for the
          reason</b></p>
      <p>Ansible is good about outputting the errors into the command line output, however if you'd
        like to view the full log for any reason the location is:</p>
      <p>
        <codeblock>~/.ansible/ansible.log</codeblock>
      </p>
      <p>This log is updated real time as you run ansible playbooks.</p>
      <note type="tip">Use grep to parse through the log. Usage: <codeph>grep &lt;text>
          ~/.ansible/ansible.log</codeph></note>
      <p><b>Wait for SSH phase in bm-reimage.yml hangs </b></p>
      <p>This issue has been observed during deployment to systems configured with QLogic based
        BCM578XX network adapters utilizing the bnx2x driver and is currently under investigation.
        The symptom manifests following a cold boot during deployment at the "wait for SSH" phase in
        bm-reimage.yml which will result in a hang and eventually timeout, causing the baremetal
        install to fail. The presence of this particular issue can be further confirmed by
        connecting to the remote console of the server via iLO or by checking the server's dmesg
        output for the presence of bnx2_panic_dump messages, similar to the following:
        <codeblock>
bnx2x: [bnx2x_prev_unload_common:10433(eth%d)]Failed to empty BRB, hope for the best  ...
bnx2x: [bnx2x_stats_update:1268(eth0)]storm stats were not updated for 3 times
bnx2x: [bnx2x_stats_update:1269(eth0)]driver assert
bnx2x: [bnx2x_panic_dump:929(eth0)]begin crash dump -----------------  .....
bnx2x: [bnx2x_panic_dump:1163(eth0)]end crash dump -----------------</codeblock>
        This workaround is completed by rebooting the server.</p>
    </section>
      <section id="freezer">
      <p><b>Freezer installation fails if an independent network is used for the
        External_API.</b></p>
      <p> Currently the Freezer installation fails if an independent network is used for the
        External_API. If you intend to deploy the External API in Beta 2 on an independent network,
        the following changes need to be made: </p>
      <p>In <b>roles/freezer-agent/defaults/main.yml</b> add the following line:
        <codeblock>backup_freezer_api_url: "{{ FRE_API | item('advertises.vips.private[0].url', default=' ') }}"</codeblock>
        In <b>roles/freezer-agent/templates/backup.osrc.j2</b> add the following line:
        <codeblock>export OS_FREEZER_URL={{ backup_freezer_api_url }}</codeblock>
      </p>
      </section>
    <section id="imageFailure">
      <b>Soft lockup at imaging </b> When imaging your nodes, if you see a kernel error of the type
      "BUG: soft lockup - CPU#10 stuck...." you should reset the node and make sure it is imaged
      properly next time. Note that depending on when you get the error, you may have to rerun
      <codeph>cobbler-deploy.yml</codeph>. If the bm-reimage playbook says it failed to image the node, then cobbler
      knows this has occurred and you can reset the node. If not, you can follow the instructions
      above for <xref href="#reimage" format="dita">reimaging the
        node</xref>.</section>
  </body>
</topic>
