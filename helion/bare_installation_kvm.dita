<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="install_kvm">
  <title>Installing HP Helion <tm tmtype="reg">OpenStack</tm> on Baremetal for KVM
    Hypervisor</title>
  <body>
    <section id="important-notes"><title>Important Notes</title>
      <ul>
        <li>If you are looking for information about when to use the GUI installer and when to use
          the CLI, see the <xref href="installation_overview.dita#install_overview">Installation
            Ovweview</xref>.</li>
        <li>We have put together a <xref href="preinstall_checklist.dita">Pre-Installation
            Checklist</xref> that should help with the recommended pre-installation tasks.</li>
        <li>Ensure the <xref href="hardware.dita">minimum hardware requirements</xref> are met in
          your environment.</li>
        <li>There is no requirement to have a dedicated network for OS-install and system
          deployment. More information can be found on the <xref href="supportedconfigs.dita"
            >Supported Configuration</xref> page.</li>
        <li>If you run into issues during installation, we have put together a list of <xref
            href="installation_troubleshooting.dita">Troubleshooting Steps</xref> you can
          reference.</li>
        <li>Read over the page about the <xref href="input_model.dita">Helion OpenStack 2.0 Input
            Model</xref> to learn about the configuration options for your cloud.</li>
        <li>Make sure <b>all disks on the system(s) are wiped</b> before you begin the install. (For
          Swift, refer to <xref
            href="swift/allocating_disk_drives.dita#allocating-disk-drives/requirement-disk-device"
            >Swift Requirements for Device Group Drives</xref>)</li>
        <li>The <codeph>/dev/sda</codeph> disk on your systems will be used for the operating
          system.</li>
        <li>Both HP Linux for HP Helion OpenStack and HP Helion OpenStack are part of the ISO you
          will download from the <xref
            href="https://helion.hpwsportal.com/catalog.html#/Category/%7B%22categoryId%22%3A10311%7D/Show"
            format="html" scope="external">Helion Downloads</xref> page. There is only one download;
          it includes both the operating system and the Helion OpenStack installer in one ISO.</li>
        <li>All machines of a given role should be the same configuration.</li>
        <li>The machine hosting the deployer and all baremetal systems must be connected to a
          management network. Nodes on this management network must be able to reach the iLO
          subsystem of each baremetal system to enable host reboots as part of the install process.
          The HP Helion OpenStack architecture requires that the IPMI network is a separate network
          and that a route exists from the management network to the IPMI network for iLO
          access.</li>
      </ul>
    </section>
    <section id="Prereqs">
      <title>Before You Start</title>
      <note type="important">We have put together a <xref href="preinstall_checklist.dita"
          >Pre-Installation Checklist</xref> that should help with the recommended pre-installation
        tasks.</note>
      <p>Prepare your baremetal hardware, as follows, on all nodes:</p>
      <ul>
        <li>Set up the iLO Advanced license in the iLO configuration. Make sure the iLO user has
          admin privileges.</li>
        <li> HP Helion OpenStack 2.0 Beta 2 will detect and use the "BIOS" mode you have selected
          for each node; UEFI or legacy BIOS. UEFI support is new in Beta 2.</li>
        <li>Ensure that the network interface to be used for PXE installation has PXE enabled.</li>
        <li>Ensure that the other network interfaces have PXE disabled.</li>
        <li>Ensure that any logical drives (LUN) for the servers you will be using are created to
          meet the disk requirements outlined in the <xref href="hardware.dita">Minimum Hardware
            Requirements</xref>.</li>
      </ul>
    </section>
    <section id="DeployerInstall">
      <title>Set up the Deployer</title>
      <ol>
        <li>Download the HP Helion OpenStack Deployer ISO from the <xref
            href="https://helion.hpwsportal.com/catalog.html#/Category/%7B%22categoryId%22%3A10311%7D/Show"
            format="html" scope="external">Helion Downloads</xref> page after signing up and being
          approved for the program.</li>
        <li>Boot your deployer from the ISO. Insert the CD ROM in the Virtual Media drive on the
          iLO.</li>
        <li>Enter "install" to start installation. <note>"install" is all lower case</note></li>
        <li>Select the language.</li>
        <li>Select the location.</li>
        <li>Select the keyboard layout.</li>
        <li>Select the primary network interface, if prompted:<ul>
            <li>Assign IP address, netmask</li>
          </ul></li>
        <li>Create new account:<ul>
            <li>Enter a username.</li>
            <li>Enter a password.</li>
            <li>Enter time zone if prompted to do so.</li>
          </ul>
        </li>
        <li>Ensure your deployer has a valid DNS nameserver in the <codeph>/etc/resolv.conf</codeph>
          file</li>
      </ol>
      <p>At the end of this section you should have a deployer node set up with hLinux on it.</p>
    </section>
    <section id="HLM_Node_Personalization">
      <title>Configure and Run the Deployer</title>
      <note>It's critical that you don't run as root. Run as the user you just created (or stack if
        you left the default of "stack"), but do not run as root.</note>
      <ol>
        <li>Log in to the deployer node as the user you created during the setup phase, and mount
          the install media at /media/cdrom, for example,
          <codeblock>sudo mount Helion-OpenStack-2.0.0-b.2-Beta2.iso /media/cdrom</codeblock></li>
        <li>Unpack the tarball that is in the <codeph>/media/cdrom/hos2.0.0/</codeph> directory:
          <codeblock>tar zxvf /media/cdrom/hos-2.0.0/hos-2.0.0-b.2-20150920T130131Z.tgz</codeblock></li>
        <li>Run the following included script:
          <codeblock>~/hos-2.0.0-b.2/hos-init.bash</codeblock></li>
        <!-- removed per DOCS-1671
        <li>You will be prompted for an SSH passphrase during initialization. Enter a passphrase if
          you want to use one, otherwise hit return for no passphrase. If you've entered a
          passphrase you will need to add a private key to ssh-agent before running Ansible
          playbooks.</li>
        <li>If you entered a passphrase for your SSH keys, execute the following commands before
          running any Ansible playbooks:
          <codeblock>
eval $(ssh-agent)
ssh-add ~/.ssh/id_rsa</codeblock></li>
-->
      </ol>
      <p>At the end of this section you should have a local directory structure, as described
        below:</p>
      <codeblock>
helion/                        Top level directory
helion/examples/               Directory contains the config input files of the example clouds
helion/my_cloud/definition/    Directory contains the config input files
helion/my_cloud/config/        Directory contains .j2 files which are symlinks to the /hos/ansible directory
helion/hos/                    Directory contains files used by the installer
</codeblock>
    </section>
    <section id="Configuration">
      <title>Configure Your Environment</title>
      <ol>
        <li>Setup your configuration files, as follows: <ol>
            <li>See the sample set of configuration files in the
              ~/helion/examples/entry-scale-with-vsa directory. The accompanying README.md file
              explains the contents of each of the configuration files.</li>
            <li>Copy the example configuration files into the required setup directory and edit them
              to contain the details of your environment:
              <codeblock>cp -r ~/helion/examples/entry-scale-with-vsa/* ~/helion/my_cloud/definition/</codeblock></li>
            <li>Begin inputting your environment information into the configuration files in the
                <codeph>~/helion/my_cloud/definition</codeph> directory. Full details of how to do
              this can be found here: <xref href="input_model.dita">Helion OpenStack 2.0 Input
                Model</xref>.</li>
          </ol></li>
        <li>Edit the <codeph>~/helion/my_cloud/config/logging/main.yml</codeph> file and under the
            <b>Elasticsearch defaults</b> section, change the value of
            <codeph>vars.elasticsearch_cluster_name</codeph> to something other than
            <codeph>elasticsearch</codeph> (bolded below): <codeblock>elasticsearch_cluster_name: "{{ LOG_SVR | item('vars.elasticsearch_cluster_name', default='<b>elasticsearch</b>') }}"</codeblock>
          <p>For example, you could use:
            <codeblock>elasticsearch_cluster_name: "{{ LOG_SVR | item('vars.elasticsearch_cluster_name', default='<b>helioncloud</b>') }}"</codeblock></p></li>
        <li>Commit your configuration to the <xref href="using_git.dita">local git repo</xref>, as
          follows: <codeblock>cd ~/helion/hos/ansible
git add -A
git commit -m "My config or other commit message"
</codeblock>
          <note>This step needs to be repeated any time you make changed to your configuration files
            before you move onto the following steps.</note></li>
      </ol>
    </section>
    <section id="CobblerDeploy">
      <title>Deploy Cobbler </title>
      <ol>
        <li>Run the following command:
          <codeblock>export ANSIBLE_HOST_KEY_CHECKING=False</codeblock></li>
        <li>Run the following playbook:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-power-status.yml
ansible-playbook -i hosts/localhost cobbler-deploy.yml</codeblock></li>
        <li>The cobbler-deploy stage of the installation now prompts for a password. The entered
          value is used to set a user-defined password for subsequent node installs so that a user
          can gain console/terminal access to the nodes. For example, if a node maintenance is
          required or if the SSH keys are lost. The value is encrypted and placed in the kickstart
          for the node installs.<p>The password prompts look like this:</p>
          <codeblock>Enter the password that will be used to access provisioned nodes:
confirm Enter the password that will be used to access provisioned nodes:</codeblock>
          <p>Alternatively, you can also specify this password in the ansible playbook command like
            this:</p>
          <codeblock>ansible-playbook -i hosts/localhost cobbler-deploy.yml -e hlmuser_password="&lt;password>"</codeblock></li>
      </ol>
    </section>
    <section id="NodeProvision"><title>Provision the Nodes</title>
      <ol>
        <li>Run the following command, which will reimage all the nodes using PXE. Note: change
          directories to /helion/hos/ansible if not already
          there:<codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-reimage.yml</codeblock></li>
        <li>The script will wait for the nodes to install and come back up.</li>
      </ol>
    </section>
    <section id="run-config-processor"><title>Run the Configuration Processor</title>
      <ol>
        <li>Run the configuration processor, as follows:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock>
          The configuration processor output is placed onto the following two private branches of
          the git repo: <ul>
            <li>staging-ansible</li>
            <li>staging-cp-persistent</li>
          </ul>
          <note>The configuration processor may generate the following warnings which can be
              <b>safely ignored</b>:
            <codeblock>
################################################################################
# The configuration processor completed with warnings.
#   ans-host-vars-2.0         WRN: Unknown service 'vsa'as consumer of device-group vsa-datain disk-model DISK_SET_VSA.
#   ans-host-vars-2.0         WRN: Unknown service 'vsa'as consumer of device-group vsa-cachein disk-model DISK_SET_VSA.
################################################################################</codeblock>
          </note>
          <note>See <xref href="using_git.dita">Using Git for Configuration Management</xref> for
            more information.</note>
        </li>
        <li>Check your configuration: <ol>
            <li>You can review the ansible change by running the following command:
              <codeblock>git show staging-ansible</codeblock></li>
          </ol>
        </li>
      </ol>
    </section>
    <section id="validate_swift"><title>Validate Object Storage (Optional)</title>
      <ol>
        <li><p>To validate object storage cloud model, execute the following command on the
            deployer:</p>
          <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts _swift-validate-input-model.yml</codeblock>
          <p>If any error is raised when you validate the object storage, refer to <xref
              href="swift/troubleshooting.dita">Swift-Troubleshooting</xref></p></li>
      </ol>
    </section>
    <section id="deploy"><title>Deploy the Cloud</title>
      <ol>
        <li>Use the playbook below to create a deployment directory:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock></li>
        <li>Run your "verb_host" commands using the following steps: <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts site.yml</codeblock>
          <note>The step above runs osconfig to configure the cloud and hlm-deploy, to deploy the
            cloud. Therefore, this step may run for quite some time while all the nodes are
            configured (perhaps 45 minutes or more, depending on the number of nodes, to a
            degree).</note>
        </li>
        <li>Verify that the network is working correctly. Ping each IP (excluding VSA-BLK and VIPs)
          from the /etc/hosts file from one of the controller nodes.</li>
      </ol>
    </section>
    <section id="cinder"><title>Install and Configure a Block Storage Backend (Optional)</title>
      <p>There are options for the Block Storage backend notated below. Without a valid backend your
        Block Storage (Cinder) implementation will not be usable. These documents will assist you in
        installing and configuring a backend solution.</p>
      <p><b>Ceph</b></p>
      <ul>
        <li><xref href="cinder/ceph/ceph_overview.dita">Ceph Overview</xref></li>
        <li><xref href="cinder/ceph/ceph_deploy.dita">Ceph Installation and
          Configuration</xref></li>
      </ul>
      <p><b>VSA</b></p>
      <ul>
        <li><xref href="cinder/vsa/vsa.dita">VSA Installation and Configuration</xref></li>
      </ul>
      <p><b>3PAR</b></p>
      <ul>
        <li><xref href="cinder/3Par/3par_configuration.dita">3PAR Installation and
            Configuration</xref></li>
      </ul>
    </section>
    <section id="post-installation"><title>Post-Installation Verification and Administration</title>
      <p>We recommend the following post-installation steps:</p>
      <ul>
        <li><xref href="installation_verification.dita">Verify the installation using Tempest's
            embedded tests.</xref></li>
        <li>Go through the <xref href="postinstall_checklist.dita">Post-Installation
            Checklist</xref> for common administrative tasks.</li>
      </ul>
    </section>
  </body>
</topic>
