<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="install_kvm_ceph">
  <title>HP Helion <tm tmtype="reg">OpenStack</tm> 2.0: Installation for KVM Hypervisor and
    Ceph</title>
  <body>
    <p>This page describes configuration, installation, and the integration of Ceph Block Storage
      with HP Helion<tm tmtype="reg">OpenStack</tm>2.0. After the installation of Ceph you can
      perform the OpenStack operations as documented in this page. </p>
    <section>
      <title id="preq">Prerequisite</title>
      <ul id="ul_pmb_s1m_rt">
        <li>The deployer node must be setup before deploying Ceph. For more details on the
          installation of deployer node, refer to <xref
            href="../../install_entryscale_kvm_vsa.dita#install_kvm">installation guide.</xref></li>
        <li>You can deploy monitor service on a dedicated resource. Ensure to modify your
          environment after deploying the deployer node. For more details refer to <xref
            href="deploy_monitor_stand_alone_node.dita#topic_ah5_4yx_qt">Install a monitor service
            on a dedicated resource node</xref>.</li>
      </ul>
      <p/>
    </section>
    <section>
      <title id="install-procedure">Installation Procedure</title>
      <p>Perform the following procedures to configure, install, and the integrate the Ceph Block
        Storage with HP Helion OpenStack 2.0.</p>
    </section>
    <section>
      <p>
        <ol id="ol_evc_k11_gt">
          <li>Login to the deployer node.</li>
          <li>Copy the example configuration files into the required setup directory and edit them
            to contain the details of your environment:
            <codeblock>cp -r ~/helion/examples/entry-scale-kvm-ceph/* ~/helion/my_cloud/definition/</codeblock>Begin
            inputting your environment information into the configuration files in the
              <codeph>~/helion/my_cloud/definition</codeph> directory. Full details of how to do
            this can be found here: <xref href="input_model.dita">Helion OpenStack 2.0 Input
              Model</xref>. </li>
          <li>Edit the file <codeph>disks_osd.yml</codeph> and enter the details for the additional
            disks meant for OSD data and journal
              filesystems.<codeblock>vi <codeph>disks_osd.yml</codeph></codeblock><p><?oxy_custom_start type="oxy_content_highlight" color="255,255,0"?>How
              to edit osd.yml file??<?oxy_custom_end?></p><note>Ensure that disks designated to be
              used for the OSD data and journal storage must be in a clean state (i.e. any existing
              partitions must be deleted).</note></li>
          <li>Editable parameters for Ceph are available in the following locations:<ul
              id="ul_jbn_nj5_kt">
              <li><codeph>~/helion/my_cloud/config/ceph/settings.yml</codeph><p>In the
                    <codeph>settings.yml</codeph> file, you can edit the following parameters:<ul
                    id="ul_ocp_ty5_kt">
                    <li>fsid</li>
                    <li>ceph clusters</li>
                    <li>osd_settle_time</li>
                    <li>OSD_journal_size</li>
                  </ul></p></li>
              <li>
                <p>Add any additional configuration parameters for Ceph in the same file
                    (<codeph>settings.yml</codeph> file) under the 'extra:' category as
                  follows:<codeblock>extra:
  osd:
    journal max write entries: 200</codeblock></p>
              </li>
              <li>
                <p><codeph>~/helion/my_cloud/config/ceph/user_model.yml</codeph></p>
                <p>The <codeph>user_model.yml</codeph> has the editable values for the different
                  pools created by HP Helion OpenStack.</p>
              </li>
            </ul></li>
          <li> Commit your configuration to a <xref href="../../using_git.dita">local
              repository</xref>:<codeblock>cd ~/helion/hos/ansible
git add -A
git commit -m "&lt;commit message>"</codeblock><note>
              Enter your commit message &lt;commit message></note></li>
          <li>Run the configuration
            processor:<codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock></li>
          <li>Run the following command to create a deployment
            directory.<codeblock>cd ~/helion/hos/ansible
<codeph>ansible-playbook -i hosts/localhost ready-deployment.yml</codeph></codeblock></li>
          <li>Run the following ansible
            playbook:<codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts site.yml</codeblock></li>
        </ol>
      </p>
    </section>
    <p>Ceph Monitor service is deployed on the Controller Nodes and OSD's are deployed as separate
      nodes (Resource Nodes).</p>
    <p id="run-ceph-client-package"><b>Run Ceph Client Packages</b></p>
    <p>Ceph can be used as backend for nova-compute, glance, cinder-volume and cinder-backup. The
      nodes running these services should have a client installed on it. Use
        <codeph>ceph-client-prepare.yml</codeph> to deploy client on respective nodes.</p>
    <p><!--Execute the following command to install the Ceph client packages on controller nodes. --></p>
    <p>
      <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts ceph-client-prepare.yml</codeblock>
    </p>
    <p>This will also create Ceph users and Ceph pools on the resource nodes.</p>
  </body>
</topic>
