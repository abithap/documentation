<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_flx_j2b_ws">
  <title>ESX Installation </title>
  <body>
    <section>
      <title>Known Restrictions</title>
      <ul>
        <li>Ensure the <xref href="hardware.dita">minimum hardware requirements</xref> are met.</li>
        <li>All disks on the system(s) will be wiped: /dev/sda will be used for the OS but all other
          disks will be wiped.</li>
        <li>The deployer node must use the HP Linux for HP Helion OpenStack ISO, which can be
          downloaded from the <xref
            href="https://helion.hpwsportal.com/catalog.html#/Category/%7B%22categoryId%22%3A10311%7D/Show"
            format="html" scope="external">Helion Downloads</xref> page.</li>
        <li>Three NIC are tested, one 1G used for PXE and two bonded 10G for everything else. All
          machines can net boot from PXE and use the deployer as a DHCP server.</li>
        <li>All machines of a single type should be the same, that is, all computes,
          <?oxy_delete author="sharmabi" timestamp="20150819T155733+0530" content="all VSAs"?>, and
          so on.</li>
        <li>The deployer node must be a dedicated node in
          Beta<?oxy_delete author="sharmabi" timestamp="20150819T155748+0530" content="0"?><?oxy_insert_start author="sharmabi" timestamp="20150819T155748+0530"?>1<?oxy_insert_end?>.</li>
        <li>The machine hosting the deployer and all baremetal systems must be connected to a
          management network. Nodes on this management network must be able to reach the iLO
          subsystem of each baremetal system to enable host reboots as part of the install process.
          The HP Helion OpenStack architecture requires that the IPMI network is a separate network
          and that a route exists from the management network to the IPMI network for iLO
          access.</li>
      </ul>
    </section>
    <section id="Prereqs">
      <title>Before You Start</title>
      <p>Prepare your baremetal hardware, as follows, on all nodes:</p>
      <ul>
        <li>Set up the iLO Advanced license in the iLO configuration.</li>
        <li>Switch from UEFI to Legacy BIOS.</li>
        <li>Ensure that the network to be used for PXE installation has PXE enabled.</li>
        <li>Ensure that the other networks have PXE disabled.</li>
      </ul>
    </section>
    <section id="DeployerInstall">
      <title>Set up the Deployer</title>
      <ol>
        <li>Create LUN(s), if required.</li>
        <li>Download the HP Linux for HP Helion OpenStack Deployer ISO from the <xref
            href="https://helion.hpwsportal.com/catalog.html#/Category/%7B%22categoryId%22%3A10311%7D/Show"
            format="html" scope="external">Helion Downloads</xref> page.</li>
        <li>Boot your deployer from the ISO.</li>
        <li>Enter "install" to start installation.</li>
        <li>Select the language.</li>
        <li>Select the location.</li>
        <li>Select the keyboard layout.</li>
        <li>Select the primary network interface, if prompted:<ul>
            <li>Assign IP address, netmask</li>
          </ul></li>
        <li>Create new account:<ul>
            <li>Enter a username.</li>
            <li>Enter a password.</li>
            <li>Enter time zone if prompted to do so.</li>
            <li>Synchronize the time on all nodes manually. NTP will be installed later.</li>
          </ul></li>
      </ol>
      <p>At the end of this section you should have a deployer node set up with hLinux on it.</p>
    </section>
    <section id="HLM_Node_Personalization">
      <title>Configure and Run the Deployer</title>
      <ol>
        <li>On the deployer node, enter the following command to create the SSH keypair if one is
          not already present:<codeblock>ssh-keygen -t rsa</codeblock>
        </li>
        <li>Add ~/.ssh/id_rsa.pub to ~/.ssh/authorized_keys file:
          <codeblock>cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys</codeblock></li>
        <li>Confirm that ssh localhost works without a password and that you can get from external
          sources, both with and without sudo.</li>
        <li>Mount the install media at /media/cdrom, for example,
          <codeblock>sudo mount /media/cdrom</codeblock></li>
        <li>Unpack the following tarball:
          <codeblock>tar zxvf /media/cdrom/hos-2.0.0/hlm-deployer-2.0.0-20150805T115313Z.tgz</codeblock></li>
        <li>Run the following included script:
          <codeblock>~/hlm-deployer/hlm-init-2.0.0.bash</codeblock></li>
      </ol>
      <p>At the end of this section you should have a local directory structure, as described
        below:</p>
      <codeblock>
helion/                        Top level directory
helion/examples/               Directory contains the config input files of the example clouds
helion/my_cloud/definition/    Directory contains the config input files
helion/my_cloud/config/        Directory contains .j2 files which are symlinks to the /hlm/ansible directory
helion/hlm/                    Directory contains files used by the installer
</codeblock>
    </section>
    <section id="Configuration">
      <title>Configure Your Environment</title>
      <ol>
        <li>Set up your configuration files, as follows: <ol>
            <li>See the sample set of configuration files in the
              ~/helion/examples/one-region-poc-with-<?oxy_delete author="sharmabi" timestamp="20150819T115047+0530" content="vsa"?><?oxy_insert_start author="sharmabi" timestamp="20150819T115047+0530"?>esx<?oxy_insert_end?>
              directory. The accompanying README.md file explains the contents of each of the
              configuration files.</li>
            <li>Copy the example configuration files
              <?oxy_delete author="sharmabi" timestamp="20150819T115054+0530" content="into"?><?oxy_insert_start author="sharmabi" timestamp="20150819T115055+0530"?>in<?oxy_insert_end?>
              the required setup directory and edit them as required:
              <codeblock>cp -r ~/helion/examples/one-region-poc-with-<?oxy_delete author="sharmabi" timestamp="20150819T115030+0530" content="vsa"?><?oxy_insert_start author="sharmabi" timestamp="20150819T115030+0530"?>esx<?oxy_insert_end?>/* ~/helion/my_cloud/definition/</codeblock>
              The configuration files for editing can be found at the following location: <codeblock>~/helion/my_cloud/definition/data</codeblock><ul>
                <li>The baremetalConfig.yml file should specify the server information for your
                  environment.</li>
                <li>The servers.yml file contains the IP address information for the
                  hardware<?oxy_insert_start author="sharmabi" timestamp="20150819T155831+0530"?>
                  for controller nodes<?oxy_insert_end?>.</li>
                <li>The networks.yml file contains networking information.</li>
                <li>The control_plane.yml file contains information about the services that will be
                  installed.</li>
                <li>In the <codeph>net_interfaces.yml</codeph> file, replace all instances of
                  “bond-mode: 1” to “bond-mode: active-backup”.</li>
              </ul></li>
          </ol></li>
        <li>Run the configuration processor, as follows: <codeblock>cd ~/helion/hlm/ansible</codeblock>
          <codeblock>ansible-playbook -i hosts/localhost config-processor-run<?oxy_delete author="sharmabi" timestamp="20150819T155903+0530" content="_v2"?>.yml</codeblock>
          Note that if the installer tells you to run ansible-playbook -i hosts/localhost
          config-processor-run.yml, don't. Run command as above (v2). </li>
        <li>Check the generated host files in
            <codeph>~/helion/my_cloud/stage/ansible/host_vars/</codeph> to ensure the correct IPs
          are included. If they are not, run
          <codeblock>ansible-playbook -i hosts/localhost config-processor-clean.yml</codeblock> and
          go to step 1.</li>
      </ol>
    </section>
    <section id="CobblerDeploy">
      <title>Deploy Cobbler </title>
      <ol>
        <li>Run the following command:
          <codeblock>export ANSIBLE_HOST_KEY_CHECKING=False</codeblock></li>
        <li>Run the following playbook:
          <codeblock>ansible-playbook -i hosts/localhost cobbler-deploy.yml</codeblock></li>
      </ol>
    </section>
    <section id="NodeProvision">
      <title>Provision the Nodes</title>
      <ol>
        <li>Run the following command, which will set all nodes to PXE boot and power cycle them to
          start their OS
          install:<codeblock>ansible-playbook -i hosts/localhost cobbler-provision.yml</codeblock></li>
        <li>Wait for the nodes to install. They will power down at the end. You can make waiting
          easier with the following
          command:<codeblock><codeph>ansible-playbook -i hosts/localhost cobbler-wait-for-shutdown.yml</codeph></codeblock>This
          will complete once all machines are down.</li>
        <li>Once all nodes are down, power up the recently-installed systems, using the following
          command:<codeblock>ansible-playbook -i hosts/localhost cobbler-power-up.yml</codeblock></li>
        <li>You can make waiting easier with the command below, which will complete once all
          machines are up and the SSH daemon is responding:
          <codeblock>ansible-playbook -i hosts/localhost cobbler-wait-for-ssh.yml</codeblock></li>
      </ol>
    </section>
    <section id="CloudDeploy">
      <title>Deploy the Cloud</title>
      <ol>
        <li>Run the following command: <codeblock>ansible-playbook -i hosts/verb_hosts osconfig-runV2.yml</codeblock><ol>
            <li>Verify the network is working correctly by pinging each IP (excluding VSA-BLK and
              VIPs) from the deployer node. You can find the IP addresses in
                <b>generated_files/etc/hosts</b>. To do so, run:
              <codeblock>stack@hlm:~/helion/hlm/ansible$ less generated_files/etc/hosts</codeblock></li>
          </ol>
        </li>
        <li> Edit roles/HZN-WEB/tasks/install.yml and add the following after the 'install-package'
          section:
          <codeblock>- name: HZN-WEB | install | TEMP fix horizon permissions
  sudo: yes
  command: "chown -R stack:stack {{ HORIZON_VENV_DIR }}/lib/python2.7/site-packages"</codeblock>
          the modified file should look as follows:
          <codeblock># Install pre-packaged Horizon venv from tarball
- name: HZN-WEB | install | Install Horizon
  install_package:
    name: horizon
    service: horizon
    state: present
 
- name: HZN-WEB | install | TEMP fix horizon permissions
  sudo: yes
  command: "chown -R stack:stack {{ HORIZON_VENV_DIR }}/lib/python2.7/site-packages"</codeblock></li>
        <li>Run the following command:
          <codeblock>ansible-playbook -i hosts/verb_hosts hlm-deploy.yml -e tuning_selector=medium</codeblock>
        </li>
      </ol>
    </section>
    <section id="VSA">
      <title>Install and Configure ESX Compute and OVSvAPP on vCenter</title>
      <p>The following sections describe the procedure to install and configure ESX compute and
        OVSvAPP on vCenter.<ul id="ul_jqm_zjx_ct">
          <li>Deploy a template</li>
          <li>Deploy a service</li>
          <li>Run the config processor</li>
          <li>Deploy a cloud</li>
        </ul></p>
    </section>
    <section>
      <p><b>Deploy a template</b></p>
    </section>
    <section>Perform the following steps to deploy a template:<ol id="ol_khb_dk5_bt">
        <li>Import the <codeph>hlm-shell-vm.ova</codeph> in the vCenter using the vSphere client. </li>
        <li>In the vSphere Client, click <b>File</b> and then click <b>Deploy OVF Template</b>.</li>
        <li>Follow the instructions in the wizard to specify the data center, cluster, and node to
          install. Refer to the VMWare vSphere documentation as needed. </li>
      </ol></section>
    <section><b>Deploy a Service</b><p>Execute the following steps form the deployer to deploy a
        service using the EON CLI</p><p>
        <ol id="ol_t1q_jl5_bt">
          <li>Source <codeph>service.osrc</codeph>.
              <p><!--<p>unset OS_DOMAIN_NAME</p><p>export OS_IDENTITY_API_VERSION=3</p><p>export OS_AUTH_VERSION=3</p><p>export OS_PROJECT_NAME=admin</p><p>export OS_PROJECT_DOMAIN_NAME=Default</p><p>export OS_USERNAME=admin</p><p>export OS_USER_DOMAIN_NAME=Default</p><p>export OS_PASSWORD=admin</p><p>export OS_AUTH_URL=http://helion-ccp-vip-admin-KEY-API-mgmt:35357/v3</p><p>export OS_CACERT=/etc/ssl/certs/ca-certificates.cr</p>--></p></li>
          <li>Add a vCenter to the eon
              database.<codeblock><codeph>eon vcenter-add --name &lt;vCenter Name> --ip-address &lt;vCenter IP address> --username &lt;vCenter Username> --password&lt;vCenter Password> --port&lt;vCenter Port></codeph></codeblock><p>where:</p><p>
              <ul id="ul_lx4_yr5_bt">
                <li>vCenter Name - the name of the vCenter server where the service will be
                  deployed.</li>
                <li>vCenter IP address - the IP address of the vCenter server where the service will
                  be deployed.</li>
                <li>vCenter Username - the username for the vCenter administrator.</li>
                <li>vCenter Password - the password for the vCenter administrator.</li>
                <li>vCenter Port - the vCenter server port.<p><b>Sample
                  Output</b>:</p><codeblock>+------------+---------------------------------------+ 
| Property   | Value                                 | 
+-------A-----+--------------------------------------+ 
| created_at | 2014-05-09T09:01:09.513550            | 
| deleted    | False                                 | 
| deleted_at | None                                  | 
| id         | f7cb3811-0d33-44ec-a54a-a69cf7615f5e  | 
| ip_address | 10.1.192.98                           | 
| name       | Test_vcenter                          | 
| password   | &lt;SANITIZED>                           | 
| port       | 443                                   | 
| type       | vcenter                               | 
| updated_at | 2014-05-09T09:53:33.500434            | 
| username   | cdl\moonshotblr                       | 
+------------+---------------------------------------+</codeblock></li>
              </ul>
            </p></li>
          <li>Run the following command to update the network
              configuration:<codeblock><codeph>eon get-network-info-template --filename &lt;<b> file name</b>></codeph></codeblock><p>For
              example:<codeblock><codeph>eon get-network-info-template --filename &lt;<b>net_conf.json</b>></codeph></codeblock></p></li>
          <li>Modify the json file as per your
            environment.<codeblock>vi &lt;<b>file name</b>></codeblock></li>
          <li>Set the network information for a vCenter. <codeblock><codeph>eon set-network-info --vcenter-id &lt;vCenter ID> --config-json &lt;abc.json></codeph></codeblock><p>
              <note>The vcenter ID is generated when you execute the above (<b>step 3</b>)
                command.</note>
            </p></li>
          <li>Execute the following command to view the list of clusters for the given
              vCenter.<codeblock><codeph>eon cluster-list --vcenter-id &lt;vCenter ID></codeph></codeblock><b>Sample
              Output</b><codeblock>+------------+-----------+---------------+----------------+----------------+ 
| MOID | Name| Datacenter| Import Status | Managed Status                  | 
+------------+-----------+---------------+----------------+----------------+ 
| domain-c26 | Cluster1  | COS           | not_imported   | False          | 
| domain-c28 | Cluster2  | COS           | not_imported   | False          | 
+------------+-----------+---------------+----------------+----------------+</codeblock></li>
          <li>Import the cluster for the EON database under the given vCenter.
              <codeblock><codeph>eon cluster-import --vcenter-id &lt;vCenter ID> --cluster-name &lt;Cluster Name> --cluster-moid &lt;Cluster Moid></codeph></codeblock><p>where:</p><p>
              <ul id="ul_osx_bx5_bt">
                <li>vCenter ID: ID of the vcenter containing the cluster.</li>
                <li>Cluster Name: the name of the cluster that needs to be imported.</li>
                <li>cluster Moid: Moid of the cluster that needs to be imported.</li>
              </ul>
              <codeblock>+---------------+--------------------------------------+ 
| Property      | Value                                | 
+---------------+--------------------------------------+ 
| id            | 7e7ed17d-de71-4207-af5f-3c5fca847d3d | 
| name          | Cluster1                             | 
| resource_moid | domain-c26                           | 
| resource_uuid | 7e7ed17d-de71-4207-af5f-3c5fca847d3d | 
| state         | imported                             | 
| vcenter_id    | f7cb3811-0d33-44ec-a54a-a69cf7615f5e | 
+---------------+--------------------------------------+</codeblock>
            </p>One vCenter can have multiple clusters. But it allows you to import only one cluster
            at a time.</li>
          <li>Activate the cluster for the selected
            vCenter.<codeblock><codeph>eon cluster-activate --vcenter-id &lt;vCenter ID> --cluster-moid &lt;Cluster Moid> </codeph></codeblock></li>
        </ol>
      </p></section>
    <p><b>Sample Output</b></p>
    <p><b>required sample out for the activated cluster</b></p>
    <section><b>Run the config processor</b></section>
    <section>
      <p>Execute the following commands:</p>
      <p>
        <codeblock><codeph>cd ~/helion/hlm/ansible</codeph>
<codeph>ansible-playbook -i hosts/localhost config-processor-run.yml</codeph></codeblock>
      </p>
    </section>
    <section><b>Deploy a cloud</b></section>
    <section>
      <p>Execute the following command to deploy a
        cloud:<codeblock><codeph>ansible-playbook -i hosts/verb_hosts hlm-deploy.yml -e tuning_selector=medium</codeph></codeblock></p>
    </section>
    <section><b>Verification Steps</b><p><b>Change this section as per esx</b><ol id="ol_o5y_yyv_bt">
          <li>This step may be used to verify your cloud installation. Note that running the command
            below will download a cirros image format the internet, upload it to Glance and create a
            Neutron external
              network.<codeblock>ansible-playbook -i hosts/verb_hosts hlm-cloud-configure.yml</codeblock><note>You
              can optionally specify the external network CIDR here too. If you choose not to
              exercise this option or use a wrong value, the VMs will not be accessible over the
              network.</note><codeblock>ansible-playbook -i hosts/verb_hosts hlm-cloud-configure.yml -e EXT_NET_CIDR=10.240.96.0/20</codeblock></li>
          <li>Run the following command, which will replace <codeph>/etc/hosts</codeph> on the
            deployer:
            <codeblock>ansible-playbook -i hosts/localhost cloud-client-setup.yml</codeblock></li>
          <li>As the /etc/hosts no longer have entries for HLM, sudo commands may become a bit
            slower. To fix this issue, once this step is complete, add "hlm" after "127.0.0.1
            localhost". The result will look like
            this:<codeblock>...
# Localhost Information
127.0.0.1 localhost hlm</codeblock></li>
        </ol></p></section>
  </body>
</topic>
